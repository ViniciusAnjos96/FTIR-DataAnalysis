{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO6DbxWnjRSAx1Sj+Dxi3iq"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQYjYeB1z86g"
      },
      "outputs": [],
      "source": [
        "# t-distributed Stochastic Neighbor Embedding\n",
        "# Change the NAME.csv\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "try:\n",
        "    df = pd.read_csv('NAME.csv')\n",
        "except FileNotFoundError:\n",
        "    print(\"Erro: Arquivo 'NAME.csv' não encontrado. Por favor, verifique o nome e o caminho do arquivo.\")\n",
        "    # You might want to handle this error appropriately, e.g., exit or provide instructions.\n",
        "    exit()\n",
        "\n",
        "\n",
        "# Assuming the first column is the class label and the rest are features (wavenumbers)\n",
        "# Separate the class labels and the spectral data\n",
        "classes = df.iloc[:, 0]\n",
        "spectra = df.iloc[:, 1:]\n",
        "\n",
        "# Convert the spectral data to a numpy array\n",
        "X = spectra.values\n",
        "y = classes.values\n",
        "\n",
        "# Perform t-SNE\n",
        "# Adjust parameters like n_components, perplexity, n_iter as needed\n",
        "tsne = TSNE(n_components=2, random_state=42, perplexity=30, n_iter=300)\n",
        "X_embedded = tsne.fit_transform(X)\n",
        "\n",
        "# Plot the results\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "# Get unique classes\n",
        "unique_classes = np.unique(y)\n",
        "\n",
        "# Define colors for each class (you can customize this)\n",
        "colors = ['r', 'g', 'b', 'c', 'm', 'y', 'k']\n",
        "# Ensure you have enough colors for your classes\n",
        "if len(unique_classes) > len(colors):\n",
        "    print(f\"Aviso: Existem mais classes ({len(unique_classes)}) do que cores disponíveis ({len(colors)}). Algumas classes terão a mesma cor.\")\n",
        "    # You might want to use a colormap instead for more classes\n",
        "\n",
        "for i, cls in enumerate(unique_classes):\n",
        "    # Filter data points belonging to the current class\n",
        "    indices = y == cls\n",
        "    plt.scatter(X_embedded[indices, 0], X_embedded[indices, 1], label=f'Classe {cls}', color=colors[i % len(colors)], alpha=0.7)\n",
        "\n",
        "plt.title('t-SNE of FTIR Spectra')\n",
        "plt.xlabel('t-SNE Component 1')\n",
        "plt.ylabel('t-SNE Component 2')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Classifiaction Report\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Assuming X and y are already loaded and preprocessed from the preceding code\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "# Train a classifier (using RandomForestClassifier as an example)\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Generate the classification report\n",
        "report = classification_report(y_test, y_pred, output_dict=True)\n",
        "df_report = pd.DataFrame(report).transpose()\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Plot the classification report as a table\n",
        "fig, ax = plt.subplots(figsize=(10, len(df_report) * 0.5)) # Adjust figure size based on report size\n",
        "ax.axis('off')\n",
        "ax.axis('tight')\n",
        "\n",
        "# Create the table\n",
        "table = ax.table(cellText=df_report.values,\n",
        "                 colLabels=df_report.columns,\n",
        "                 rowLabels=df_report.index,\n",
        "                 cellLoc='center',\n",
        "                 loc='center')\n",
        "\n",
        "table.auto_set_font_size(False)\n",
        "table.set_fontsize(10)\n",
        "table.scale(1.2, 1.2) # Adjust scale for better readability\n",
        "\n",
        "plt.title('Classification Report', fontsize=14, y=1.05)\n",
        "plt.show()\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "7QJrbWBw98iX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Local Interpretable Model-agnostic Explanations\n",
        "\n",
        "!pip install lime\n",
        "\n",
        "import lime\n",
        "import lime.lime_tabular\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Assuming you have a trained model. Let's train a simple RandomForestClassifier for demonstration.\n",
        "# If you already have a trained model, replace this section with loading your model.\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Train a classifier (replace with your actual model training)\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model (optional)\n",
        "y_pred = model.predict(X_test)\n",
        "print(f\"Model Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
        "\n",
        "# LIME Explanation\n",
        "# Create a LIME explainer\n",
        "# feature_names should correspond to the columns in your spectral data\n",
        "feature_names = spectra.columns.tolist()\n",
        "class_names = [str(cls) for cls in unique_classes] # Convert class names to strings\n",
        "\n",
        "explainer = lime.lime_tabular.LimeTabularExplainer(\n",
        "    training_data=X_train,\n",
        "    feature_names=feature_names,\n",
        "    class_names=class_names,\n",
        "    mode='classification' # Or 'regression' if it's a regression problem\n",
        ")\n",
        "\n",
        "# Choose an instance from the test set to explain (e.g., the first instance)\n",
        "instance_idx = 0\n",
        "instance_to_explain = X_test[instance_idx]\n",
        "\n",
        "# Explain the instance\n",
        "explanation = explainer.explain_instance(\n",
        "    data_row=instance_to_explain,\n",
        "    predict_fn=model.predict_proba, # Use predict_proba for classification\n",
        "    num_features=5 # Number of features to show in the explanation\n",
        ")\n",
        "\n",
        "# Visualize the explanation\n",
        "# In a Jupyter/Colab notebook, this will display an interactive visualization\n",
        "explanation.show_in_notebook(show_table=True, show_all=False)\n",
        "\n",
        "# You can also get the explanation as text\n",
        "# print(explanation.as_text())\n",
        "\n",
        "# Or as a list of tuples (feature, weight)\n",
        "# print(explanation.as_list())\n",
        "\n"
      ],
      "metadata": {
        "id": "5nN2BG8h5TfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# SHapley Additive exPlanations\n",
        "\n",
        "import numpy as np\n",
        "!pip install shap\n",
        "\n",
        "import shap\n",
        "\n",
        "# SHAP Explanation\n",
        "# Create a SHAP explainer. For tree-based models, use TreeExplainer.\n",
        "# For other models (like linear models, SVMs), you might use KernelExplainer or DeepExplainer.\n",
        "# If you have a different model type, you might need a different explainer.\n",
        "# Assuming 'model' is a scikit-learn compatible model with a 'predict_proba' or 'predict' method.\n",
        "\n",
        "# Using the trained RandomForestClassifier from the previous cell\n",
        "try:\n",
        "    explainer_shap = shap.TreeExplainer(model)\n",
        "except Exception as e:\n",
        "    print(f\"Could not create SHAP TreeExplainer. Make sure your model is compatible.\")\n",
        "    print(e)\n",
        "    # Fallback to KernelExplainer if TreeExplainer fails (more general but slower)\n",
        "    print(\"Attempting to use KernelExplainer as a fallback.\")\n",
        "    # KernelExplainer requires a background dataset\n",
        "    # A common approach is to use a sample of the training data as the background\n",
        "    background_data = shap.sample(X_train, 100) # Adjust sample size as needed\n",
        "    explainer_shap = shap.KernelExplainer(model.predict_proba if hasattr(model, 'predict_proba') else model.predict, background_data)\n",
        "\n",
        "\n",
        "# Calculate SHAP values for the test set\n",
        "# This can take some time depending on the size of your test set and model complexity\n",
        "print(\"Calculating SHAP values...\")\n",
        "shap_values = explainer_shap.shap_values(X_test)\n",
        "print(\"SHAP values calculated.\")\n",
        "\n",
        "# Visualize the SHAP results\n",
        "\n",
        "# If you are working with multi-class classification and predict_proba, shap_values will be a list of arrays, one for each class.\n",
        "# We need to decide which class's explanation to visualize or aggregate.\n",
        "# For classification, shap_values[i] corresponds to the SHAP values for the i-th class's output.\n",
        "\n",
        "# Example 1: Summary Plot (shows the distribution of SHAP values for each feature across the dataset)\n",
        "# This is useful for understanding the overall impact of features.\n",
        "# If it's a multi-class problem with predict_proba, you might want to summarize for a specific class or average.\n",
        "# Let's plot for the first class's output as an example.\n",
        "# If shap_values is a list of arrays (multi-output), choose one.\n",
        "if isinstance(shap_values, list):\n",
        "  print(\"Generating SHAP summary plot for the first class...\")\n",
        "  # Use shap_values[0] for the first class's SHAP values\n",
        "  shap.summary_plot(shap_values[0], X_test, feature_names=feature_names)\n",
        "else:\n",
        "  print(\"Generating SHAP summary plot...\")\n",
        "  shap.summary_plot(shap_values, X_test, feature_names=feature_names)\n",
        "\n",
        "\n",
        "# Example 2: Force Plot (explains a single prediction)\n",
        "# This shows how features push the prediction from the base value (average prediction) to the explained instance's prediction.\n",
        "# You need to specify an instance from the test set.\n",
        "# Again, if multi-output, choose the class index you want to explain.\n",
        "instance_idx_to_explain_shap = 0 # Same instance as the LIME example\n",
        "\n",
        "# For multi-class, you often look at the force plot for the predicted class, or the class of interest.\n",
        "# Let's get the predicted class for the chosen instance.\n",
        "# model.predict returns an array, get the first element\n",
        "predicted_class_idx = model.predict([X_test[instance_idx_to_explain_shap]])[0]\n",
        "# Find the index of this class in the unique_classes list to get the correct SHAP values.\n",
        "# Ensure unique_classes is a list or handle potential index errors\n",
        "try:\n",
        "    predicted_class_shap_index = list(unique_classes).index(predicted_class_idx)\n",
        "except ValueError:\n",
        "    print(f\"Warning: Predicted class '{predicted_class_idx}' not found in unique classes. Using index 0 for force plot.\")\n",
        "    predicted_class_shap_index = 0\n",
        "\n",
        "\n",
        "print(f\"Generating SHAP force plot for instance {instance_idx_to_explain_shap} (predicted class: {predicted_class_idx})...\")\n",
        "if isinstance(shap_values, list):\n",
        "    # For multi-output, pass the SHAP values for the relevant class\n",
        "    # Corrected: Pass the expected value for the predicted class and the SHAP values for the instance and predicted class.\n",
        "    # The shap_values are typically structured as (n_samples, n_features, n_outputs) for multi-output.\n",
        "    # We need shap_values[instance_idx, :, class_index] for the instance and class.\n",
        "    shap.force_plot(explainer_shap.expected_value[predicted_class_shap_index],\n",
        "                    shap_values[predicted_class_shap_index][instance_idx_to_explain_shap],\n",
        "                    X_test[instance_idx_to_explain_shap],\n",
        "                    feature_names=feature_names)\n",
        "else:\n",
        "    # For single output\n",
        "     shap.force_plot(explainer_shap.expected_value,\n",
        "                    shap_values[instance_idx_to_explain_shap],\n",
        "                    X_test[instance_idx_to_explain_shap],\n",
        "                    feature_names=feature_names)\n",
        "\n",
        "\n",
        "# Example 3: Dependence Plot (shows how a single feature affects the prediction across the dataset)\n",
        "# This helps visualize the relationship between a feature's value and its impact on the model output.\n",
        "# You need to specify a feature index or name. Let's pick the feature with the highest mean absolute SHAP value (from the summary plot analysis).\n",
        "# For multi-class, you might plot this for the SHAP values of a specific class.\n",
        "# Let's plot for the feature that has the biggest impact on average (based on the summary plot).\n",
        "\n",
        "if isinstance(shap_values, list):\n",
        "    # Calculate mean absolute SHAP values across all instances for the first class\n",
        "    mean_abs_shap_values = np.mean(np.abs(shap_values[0]), axis=0)\n",
        "    # Find the index of the feature with the highest mean absolute SHAP value\n",
        "    feature_to_plot_idx = np.argmax(mean_abs_shap_values)\n",
        "else:\n",
        "    # Calculate mean absolute SHAP values across all instances\n",
        "    mean_abs_shap_values = np.mean(np.abs(shap_values), axis=0)\n",
        "    # Find the index of the feature with the highest mean absolute SHAP value\n",
        "    feature_to_plot_idx = np.argmax(mean_abs_shap_values)\n",
        "\n",
        "feature_to_plot_name = feature_names[feature_to_plot_idx]\n",
        "print(f\"Generating SHAP dependence plot for feature: {feature_to_plot_name}\")\n",
        "\n",
        "if isinstance(shap_values, list):\n",
        "    # For multi-output, plot dependence for the relevant class SHAP values\n",
        "    # We are plotting dependence for the first class's SHAP values as in the summary plot\n",
        "    shap.dependence_plot(feature_to_plot_idx, shap_values[0], X_test, feature_names=feature_names, interaction_index=None) # interaction_index=None for no interaction feature\n",
        "else:\n",
        "     shap.dependence_plot(feature_to_plot_idx, shap_values, X_test, feature_names=feature_names, interaction_index=None)\n",
        "\n",
        "\n",
        "# Other SHAP plots include decision plots, waterfall plots, etc. You can explore the SHAP documentation for more options.\n",
        "# https://shap.readthedocs.io/en/latest/api.html"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "ZHjW3ydw6Igt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}