{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOtEmV7MdxnfZ7sZ0nlwLaI"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ===== Pacotes / Packages =====\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, classification_report\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ],
      "metadata": {
        "id": "oNaSbZz7XQHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 1. Ler os dados .XLSX / Read .XLSX data =====\n",
        "dados = pd.read_excel(\"NAME.xlsx\")\n",
        "print(dados.head())"
      ],
      "metadata": {
        "id": "HWdHPjmFuKeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Ler os dados .CSV / Read .CSV data ===\n",
        "dados = pd.read_csv('NAME.csv', sep=',')  # especifica o separador\n",
        "print(dados.head())"
      ],
      "metadata": {
        "id": "w7ulRSNOuQPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 2. Garantir que preditoras sejam numéricas / Ensure predictors are numeric =====\n",
        "X = dados.drop(dados.columns[0], axis=1).apply(pd.to_numeric)\n",
        "y = dados[dados.columns[0]].values.ravel()  # Classe na primeira coluna / Class in first column\n",
        "\n",
        "# ===== 3. Padronizar os dados / Standardize data =====\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# ===== Exclui NaN / Excludes NaN =====\n",
        "dados_cleaned = dados.dropna()"
      ],
      "metadata": {
        "id": "R9GvD8-iXSR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 4. Divisão treino/teste / Training/testing division =====\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=1234, stratify=y\n",
        ")\n",
        "\n",
        "print(\"Treino:\", X_train.shape, y_train.shape)\n",
        "print(\"Teste:\", X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeMsdrNXXUBy",
        "outputId": "7db72483-1c47-480b-c676-ac289e477411"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treino: (6723, 9) (6723,)\n",
            "Teste: (1681, 9) (1681,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 5. Treinar SVM / Train SVM =====\n",
        "modelo_svm = SVC(kernel=\"linear\", probability=True, random_state=1234) #testar com outros kernel = poly, rbf e sigmoid.\n",
        "modelo_svm.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "DnuFfcVGXWUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 6. Predição / Prediction =====\n",
        "y_pred_train = modelo_svm.predict(X_train)\n",
        "y_pred_test = modelo_svm.predict(X_test)\n",
        "\n",
        "print(\"Acurácia Treino (Training Accuracy):\", accuracy_score(y_train, y_pred_train))\n",
        "print(\"Acurácia Teste (Test Accuracy):\", accuracy_score(y_test, y_pred_test))"
      ],
      "metadata": {
        "id": "VK7tNyI3XYLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 7. Métricas / Metrics =====\n",
        "classes = sorted(np.unique(y))\n",
        "\n",
        "# Matriz de confusão / Confusion matrix\n",
        "conf_mat = confusion_matrix(y_test, y_pred_test, labels=classes)\n",
        "cm_df = pd.DataFrame(conf_mat, index=classes, columns=classes)\n",
        "\n",
        "# Visualização / Preview\n",
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel(\"Predict\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix - SVM\")\n",
        "plt.show()\n",
        "\n",
        "# Classification report\n",
        "print(\"\\nClassification Report Teste:\\n\")\n",
        "print(classification_report(y_test, y_pred_test, target_names=[str(c) for c in classes]))"
      ],
      "metadata": {
        "id": "y68O50_DhW1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 8. Validação Cruzada com K-Fold / K-Fold Cross-Validation =====\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Validar o modelo SVM com validação cruzada (K=5 por padrão) / Validate the SVM model with cross-validation (K=5 by default)\n",
        "cv_scores = cross_val_score(modelo_svm, X_scaled, y, cv=5)\n",
        "\n",
        "print(\"Acurácias por Fold (Accuracies per Fold):\", cv_scores)\n",
        "print(\"Acurácia Média (K-Fold) (Average Accuracy (K-Fold)):\", np.mean(cv_scores))\n",
        "print(\"Desvio Padrão da Acurácia (K-Fold) (Standard Deviation of Accuracy (K-Fold)):\", np.std(cv_scores))"
      ],
      "metadata": {
        "id": "7KjuVTcBNNdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 9. Feature Importance (para kernel linear) =====\n",
        "\n",
        "# Extrair os coeficientes do modelo (para kernel linear) / Extract model coefficients (for linear kernel)\n",
        "# Os coeficientes indicam a importância de cada feature na decisão de fronteira / The coefficients indicate the importance of each feature in the frontier decision\n",
        "coeficientes = modelo_svm.coef_[0]  # Pegando os coeficientes para a primeira classe (ajustar se necessário) / Getting the coefficients for the first class (adjust if necessary)\n",
        "\n",
        "# Obter os nomes das features / Get feature names\n",
        "nomes_features = X.columns\n",
        "\n",
        "# Criar um DataFrame para visualizar coeficientes e nomes das features / Create a DataFrame to visualize coefficients and feature names\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': nomes_features,\n",
        "    'importance': np.abs(coeficientes) # Usar valor absoluto para importância / Use absolute value for importance\n",
        "})\n",
        "\n",
        "# Ordenar as features por importância / Sort features by importance\n",
        "feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
        "\n",
        "# Visualizar as top N features (ex: top 10) / View the top N features (e.g. top 10)\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='importance', y='feature', data=feature_importance.head(20), palette='viridis')\n",
        "plt.title('Top 10 Features by Importance (Linear SVM Coefficients)')\n",
        "plt.xlabel('Importance (Absolute Coefficient Value)')\n",
        "plt.ylabel('Feature')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oZp_BSjt5NOX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}