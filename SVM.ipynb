{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyObRNPbjwkhBTQ1ND9AOxLB"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ===== Pacotes / Packages =====\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, classification_report, r2_score, roc_curve, auc\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.inspection import DecisionBoundaryDisplay"
      ],
      "metadata": {
        "id": "oNaSbZz7XQHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 1. Ler os dados .XLSX / Read .XLSX data =====\n",
        "dados = pd.read_excel(\"NAME.xlsx\")\n",
        "print(dados.head())"
      ],
      "metadata": {
        "id": "HWdHPjmFuKeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Ler os dados .CSV / Read .CSV data ===\n",
        "dados = pd.read_csv('NAME.csv', sep=';')  # especifica o separador / specifies the separator\n",
        "print(dados.head())"
      ],
      "metadata": {
        "id": "w7ulRSNOuQPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 2. Garantir que preditoras sejam numéricas / Ensure predictors are numeric =====\n",
        "X = dados.drop(dados.columns[0], axis=1).apply(pd.to_numeric)\n",
        "y = dados[dados.columns[0]].values.ravel()  # Classe na primeira coluna / Class in first column\n",
        "\n",
        "# ===== 3. Padronizar os dados / Standardize data =====\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# ===== Exclui NaN / Excludes NaN =====\n",
        "dados_cleaned = dados.dropna()"
      ],
      "metadata": {
        "id": "R9GvD8-iXSR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 4. Divisão treino/teste / Training/testing division =====\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=1234, stratify=y\n",
        ")\n",
        "\n",
        "print(\"Train:\", X_train.shape, y_train.shape)\n",
        "print(\"Test:\", X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "BeMsdrNXXUBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 5. Treinar SVM / Train SVM =====\n",
        "\n",
        "# Esse código utiliza a estratégia \"um grupo versus todos os demais\" (one-vs-rest) para a classificação multiclasse. Para fazer um grupo versus o outro (one-vs-one) acrescente: decision_function_shape='ovo'\n",
        "# This code uses the \"one group versus all others\" strategy for multiclass classification. To do one-vs-one classification add: decision_function_shape='ovo'\n",
        "\n",
        "modelo_svm = SVC(kernel=\"linear\", probability=True, random_state=1234, decision_function_shape='ovo') #testar com outros kernel / test with other kernels = linear, poly, rbf e sigmoid.\n",
        "modelo_svm.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "DnuFfcVGXWUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 6. Predição / Prediction =====\n",
        "y_pred_train = modelo_svm.predict(X_train)\n",
        "y_pred_test = modelo_svm.predict(X_test)\n",
        "\n",
        "print(\"Training Accuracy:\", accuracy_score(y_train, y_pred_train))\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred_test))"
      ],
      "metadata": {
        "id": "VK7tNyI3XYLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the number of support vectors / Número de vetores de suporte\n",
        "print(\"Number of support vectors:\", modelo_svm.support_vectors_.shape[0])"
      ],
      "metadata": {
        "id": "vbWH991uyo4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 7. Métricas / Metrics =====\n",
        "classes = sorted(np.unique(y))\n",
        "\n",
        "# Matriz de confusão / Confusion matrix\n",
        "conf_mat = confusion_matrix(y_test, y_pred_test, labels=classes)\n",
        "cm_df = pd.DataFrame(conf_mat, index=classes, columns=classes)\n",
        "\n",
        "# Visualização / Preview\n",
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel(\"Predict\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix - SVM\")\n",
        "plt.show()\n",
        "\n",
        "# Classification report\n",
        "print(\"\\nClassification Report Teste:\\n\")\n",
        "print(classification_report(y_test, y_pred_test, target_names=[str(c) for c in classes]))"
      ],
      "metadata": {
        "id": "y68O50_DhW1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 8. Validação Cruzada com K-Fold / K-Fold Cross-Validation =====\n",
        "\n",
        "# Validar o modelo SVM com validação cruzada (K=5 por padrão) / Validate the SVM model with cross-validation (K=5 by default)\n",
        "cv_scores = cross_val_score(modelo_svm, X_scaled, y, cv=5)\n",
        "\n",
        "print(\"Accuracies per Fold:\", cv_scores)\n",
        "print(\"Average Accuracy (K-Fold):\", np.mean(cv_scores))\n",
        "print(\"Standard Deviation of Accuracy (K-Fold):\", np.std(cv_scores))"
      ],
      "metadata": {
        "id": "7KjuVTcBNNdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 9. Feature Importance (para kernel linear) =====\n",
        "\n",
        "# Extrair os coeficientes do modelo (para kernel linear) / Extract model coefficients (for linear kernel)\n",
        "# Os coeficientes indicam a importância de cada feature na decisão de fronteira / The coefficients indicate the importance of each feature in the frontier decision\n",
        "coeficientes = modelo_svm.coef_[0]  # Pegando os coeficientes para a primeira classe (ajustar se necessário) / Getting the coefficients for the first class (adjust if necessary)\n",
        "\n",
        "# Obter os nomes das features / Get feature names\n",
        "nomes_features = X.columns\n",
        "\n",
        "# Criar um DataFrame para visualizar coeficientes e nomes das features / Create a DataFrame to visualize coefficients and feature names\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': nomes_features,\n",
        "    'importance': np.abs(coeficientes) # Usar valor absoluto para importância / Use absolute value for importance\n",
        "})\n",
        "\n",
        "# Ordenar as features por importância / Sort features by importance\n",
        "feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
        "\n",
        "# Visualizar as top N features (ex: top 10) / View the top N features (e.g. top 10)\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='importance', y='feature', data=feature_importance.head(20), palette='viridis')\n",
        "plt.title('Top 10 Features by Importance (Linear SVM Coefficients)')\n",
        "plt.xlabel('Importance (Absolute Coefficient Value)')\n",
        "plt.ylabel('Feature')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oZp_BSjt5NOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 10. Plot classification boundaries =====\n",
        "\n",
        "def plot_decision_boundary_multiclass(model, X, y, title=\"SVM Decision Boundary (PCA 2D)\"):\n",
        "    # Reduz para 2D com PCA / Reduce to 2D with PCA\n",
        "    pca = PCA(n_components=2)\n",
        "    X_2d = pca.fit_transform(X)\n",
        "\n",
        "    # Converter rótulos de classe para numéricos para o scatter plot / Convert class labels to numeric for scatter plot\n",
        "    y_numeric, classes = pd.factorize(y)\n",
        "\n",
        "    # Modelo auxiliar só para visualização / Auxiliary model for viewing only\n",
        "    viz_model = SVC(kernel=model.kernel, C=model.C, gamma=model.gamma, decision_function_shape='ovr')\n",
        "    viz_model.fit(X_2d, y_numeric) # Treinar o modelo auxiliar com rótulos numéricos / Train auxiliary model with numeric labels\n",
        "\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(6, 5))\n",
        "\n",
        "    # Fronteira de decisão (somente 'predict') / Decision boundary ('predict' only)\n",
        "    DecisionBoundaryDisplay.from_estimator(\n",
        "        viz_model,\n",
        "        X_2d,\n",
        "        response_method=\"predict\",\n",
        "        plot_method=\"pcolormesh\",\n",
        "        cmap=\"coolwarm\",\n",
        "        alpha=0.3,\n",
        "        ax=ax\n",
        "    )\n",
        "\n",
        "    # Pontos / Points\n",
        "    scatter = ax.scatter(X_2d[:, 0], X_2d[:, 1], c=y_numeric, s=30, edgecolors=\"k\", cmap=\"coolwarm\") # Usar y_numeric para colorir os pontos / Use y_numeric to color the points\n",
        "\n",
        "    # Vetores de suporte / Support vectors\n",
        "    if hasattr(viz_model, \"support_vectors_\"):\n",
        "        ax.scatter(\n",
        "            viz_model.support_vectors_[:, 0],\n",
        "            viz_model.support_vectors_[:, 1],\n",
        "            s=150,\n",
        "            facecolors=\"none\",\n",
        "            edgecolors=\"k\"\n",
        "        )\n",
        "\n",
        "    # Criar um mapeamento manual para a legenda com os rótulos originais / Create a manual mapping for the legend with original labels\n",
        "    handles, _ = scatter.legend_elements()\n",
        "    legend = ax.legend(handles, classes, loc=\"upper right\", title=\"Classes\")\n",
        "    ax.add_artist(legend)\n",
        "\n",
        "\n",
        "    ax.set_title(title)\n",
        "    plt.show()\n",
        "\n",
        "# Usar no seu modelo já treinado (com 9 features), mas reduzindo p/ PCA 2D só no gráfico / Use on your already trained model (with 9 features), but reducing to 2D PCA only on the graph\n",
        "plot_decision_boundary_multiclass(modelo_svm, X_scaled, y, \"SVM Decision Boundary (Multiclass, PCA 2D)\")"
      ],
      "metadata": {
        "id": "ep60Vbp2yPDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use curvas individuais (multiclass ROC) quando quiser analisar o desempenho do modelo em cada classe separadamente. / Use curvas individuais (ROC multiclasse) quando quiser analisar o desempenho do modelo em cada classe separadamente.\n",
        "\n",
        "# Fit LabelEncoder to the original unique classes / Ajustar LabelEncoder às classes originais exclusivas\n",
        "label_encoder = LabelEncoder()\n",
        "y_test_encoded = label_encoder.fit_transform(y_test)\n",
        "y_pred_test_encoded = label_encoder.transform(y_pred_test)\n",
        "\n",
        "\n",
        "# Compute ROC curve and ROC area for each class / Calcular a curva ROC e a área ROC para cada classe\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "\n",
        "unique_classes = label_encoder.classes_ # Use the classes from the fitted encoder / Use as classes do codificador ajustado\n",
        "n_classes = len(unique_classes)\n",
        "\n",
        "for i in range(n_classes):\n",
        "    class_value = unique_classes[i]\n",
        "\n",
        "    # Create binary true and predicted labels for the current class (one-vs-rest)\n",
        "    y_test_binary = (y_test_encoded == i).astype(int)\n",
        "    y_pred_test_binary = (y_pred_test_encoded == i).astype(int)\n",
        "\n",
        "    # Check if the current class is present in the test set (has positive samples)\n",
        "    if np.sum(y_test_binary) > 0:\n",
        "        fpr[i], tpr[i], _ = roc_curve(y_test_binary, y_pred_test_binary)\n",
        "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "    else:\n",
        "        # If a class is not in the test set, set AUC to NaN and skip plotting its curve\n",
        "        roc_auc[i] = np.nan\n",
        "        print(f\"Warning: Class {class_value} has no positive samples in the test set. Skipping ROC curve for this class.\")\n",
        "\n",
        "\n",
        "# Plot ROC curves / Traçar curvas ROC\n",
        "plt.figure(figsize=(8, 6))\n",
        "colors = ['blue', 'red', 'green', 'orange', 'purple', 'brown', 'pink', 'gray', 'olive', 'cyan']\n",
        "for i in range(n_classes):\n",
        "    # Only plot if the AUC was calculated (class was in the test set) / Somente plote se a AUC foi calculada (a classe estava no conjunto de teste)\n",
        "    if not np.isnan(roc_auc[i]):\n",
        "        # Ensure there are enough colors / Certifique-se de que há cores suficientes\n",
        "        color = colors[i % len(colors)]\n",
        "        plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
        "                 label='ROC curve of class {0} (area = {1:0.2f})'.format(unique_classes[i], roc_auc[i]))\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
        "plt.xlim([-0.05, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Multiclass ROC Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RxByCHSvxp3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use macro-average ROC quando quiser uma visão geral do desempenho do modelo em todas as classes, sem considerar desequilíbrio entre elas. / Use ROC macro-médio quando quiser uma visão geral do desempenho do modelo em todas as classes, sem considerar desequilíbrio entre elas.\n",
        "\n",
        "# Calculate macro-average ROC curve and AUC / Calcular a curva ROC macromédia e a AUC\n",
        "# First aggregate all false positive rates / Primeiro, agregue todas as taxas de falsos positivos\n",
        "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes) if not np.isnan(roc_auc[i])]))\n",
        "\n",
        "# Then interpolate all ROC curves at this points / Em seguida, interpole todas as curvas ROC nesses pontos\n",
        "mean_tpr = np.zeros_like(all_fpr)\n",
        "for i in range(n_classes):\n",
        "    if not np.isnan(roc_auc[i]):\n",
        "        mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
        "\n",
        "# Average it and compute AUC / Calcule a média e a AUC\n",
        "mean_tpr /= sum([not np.isnan(roc_auc[i]) for i in range(n_classes)]) # Divide by the number of classes that were in the test set/ Divida pelo número de classes que estavam no conjunto de teste\n",
        "\n",
        "macro_roc_auc = auc(all_fpr, mean_tpr)\n",
        "\n",
        "# Plot macro-average ROC curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(all_fpr, mean_tpr, color='red', linestyle='-', linewidth=2,\n",
        "         label='Macro-average ROC curve (area = {0:0.2f})'.format(macro_roc_auc))\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
        "plt.xlim([-0.05, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Multiclass ROC Curve (Macro-average)')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_7BTmy66yQaX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}