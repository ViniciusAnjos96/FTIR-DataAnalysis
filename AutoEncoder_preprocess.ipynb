{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMpstkdPXO/YRyXAFHTPJ9H"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqAAInUoV0CN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, callbacks\n",
        "from scipy.signal import savgol_filter\n",
        "import scipy.sparse as sp\n",
        "import scipy.sparse.linalg as spla\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# =========================================================\n",
        "# 0. Funções de pré-processamento padrão\n",
        "# =========================================================\n",
        "\n",
        "def cut_region(wavenumbers, spectra, wn_min=400, wn_max=1800):\n",
        "    wavenumbers = np.asarray(wavenumbers, dtype=float)\n",
        "    spectra = np.asarray(spectra, dtype=float)\n",
        "    mask = (wavenumbers >= wn_min) & (wavenumbers <= wn_max)\n",
        "    return wavenumbers[mask], spectra[:, mask]\n",
        "\n",
        "def snv(X):\n",
        "    X = np.asarray(X, dtype=float)\n",
        "    mean = X.mean(axis=1, keepdims=True)\n",
        "    std = X.std(axis=1, keepdims=True)\n",
        "    return (X - mean) / std\n",
        "\n",
        "def baseline_asls(y, lam=1e5, p=0.001, niter=10):\n",
        "    y = np.asarray(y, dtype=float).ravel()\n",
        "    L = y.size\n",
        "    D = sp.diags([1, -2, 1], [0, 1, 2], shape=(L-2, L))\n",
        "    DTD = D.T @ D\n",
        "    w = np.ones(L)\n",
        "    for _ in range(niter):\n",
        "        W = sp.diags(w, 0, shape=(L, L))\n",
        "        Z = W + lam * DTD\n",
        "        z = spla.spsolve(Z, w * y)\n",
        "        w = p * (y > z) + (1 - p) * (y < z)\n",
        "    return z\n",
        "\n",
        "def apply_pipeline_standard(wavenumbers, X_raw,\n",
        "                            wn_min=400, wn_max=1800,\n",
        "                            sg_window=11, sg_poly=2,\n",
        "                            asls_lam=1e5, asls_p=0.001, asls_niter=10):\n",
        "    # 1) Corte\n",
        "    wn_cut, X_cut = cut_region(wavenumbers, X_raw, wn_min, wn_max)\n",
        "    # 2) Savitzky–Golay\n",
        "    X_sg = savgol_filter(X_cut, window_length=sg_window,\n",
        "                         polyorder=sg_poly, axis=1)\n",
        "    # 3) Baseline ASL\n",
        "    X_corrected = np.zeros_like(X_sg)\n",
        "    for i in range(X_sg.shape[0]):\n",
        "        y = X_sg[i, :]\n",
        "        b = baseline_asls(y, lam=asls_lam, p=asls_p, niter=asls_niter)\n",
        "        X_corrected[i, :] = y - b\n",
        "    # 4) SNV\n",
        "    X_snv = snv(X_corrected)\n",
        "    return wn_cut, X_snv, X_cut\n",
        "\n",
        "# =========================================================\n",
        "# 1. Leitura do CSV completo\n",
        "# =========================================================\n",
        "\n",
        "csv_path = \"NAME.csv\"\n",
        "\n",
        "df = pd.read_csv(csv_path, header=None)\n",
        "\n",
        "wavenumbers_full = df.iloc[0, 1:].astype(float).values\n",
        "df_data = df.iloc[1:, :].reset_index(drop=True)\n",
        "labels_all = df_data.iloc[:, 0].values\n",
        "X_raw_full = df_data.iloc[:, 1:].astype(float).values\n",
        "\n",
        "print(\"Total de espectros:\", X_raw_full.shape[0])\n",
        "\n",
        "# =========================================================\n",
        "# 2. Dividir em dois subconjuntos: A (treino) e B (aplicação)\n",
        "#    Exemplo: 70% para A, 30% para B\n",
        "# =========================================================\n",
        "\n",
        "indices = np.arange(X_raw_full.shape[0])\n",
        "idx_A, idx_B = train_test_split(indices, test_size=0.3, random_state=42)\n",
        "\n",
        "X_raw_A = X_raw_full[idx_A, :]\n",
        "labels_A = labels_all[idx_A]\n",
        "\n",
        "X_raw_B = X_raw_full[idx_B, :]\n",
        "labels_B = labels_all[idx_B]\n",
        "\n",
        "print(\"Conjunto A (treino AE):\", X_raw_A.shape[0], \"espectros\")\n",
        "print(\"Conjunto B (aplicação AE):\", X_raw_B.shape[0], \"espectros\")\n",
        "\n",
        "# =========================================================\n",
        "# 3. Gerar padrão ouro apenas no conjunto A\n",
        "# =========================================================\n",
        "\n",
        "wn_cut, X_target_A, X_cut_A = apply_pipeline_standard(\n",
        "    wavenumbers_full,\n",
        "    X_raw_A,\n",
        "    wn_min=400,\n",
        "    wn_max=1800,\n",
        "    sg_window=7,\n",
        "    sg_poly=2,\n",
        "    asls_lam=1e5,\n",
        "    asls_p=0.001,\n",
        "    asls_niter=10,\n",
        ")\n",
        "\n",
        "print(\"Região cortada:\", wn_cut[0], \"a\", wn_cut[-1], \"cm-1\")\n",
        "print(\"X_cut_A (entrada AE):\", X_cut_A.shape)\n",
        "print(\"X_target_A (padrão ouro):\", X_target_A.shape)\n",
        "\n",
        "# =========================================================\n",
        "# 4. Preparar dados de treino/val/testo dentro do conjunto A\n",
        "# =========================================================\n",
        "\n",
        "# z-score por variável de entrada e alvo\n",
        "mean_in = X_cut_A.mean(axis=0, keepdims=True)\n",
        "std_in = X_cut_A.std(axis=0, keepdims=True)\n",
        "X_in_A_scaled = (X_cut_A - mean_in) / std_in\n",
        "\n",
        "mean_tgt = X_target_A.mean(axis=0, keepdims=True)\n",
        "std_tgt = X_target_A.std(axis=0, keepdims=True)\n",
        "X_target_A_scaled = (X_target_A - mean_tgt) / std_tgt\n",
        "\n",
        "# Adiciona eixo de canal\n",
        "X_in_A_scaled = X_in_A_scaled[..., np.newaxis]\n",
        "X_target_A_scaled = X_target_A_scaled[..., np.newaxis]\n",
        "\n",
        "# Divide A em treino/val/testo\n",
        "X_train_in, X_temp_in, X_train_tgt, X_temp_tgt = train_test_split(\n",
        "    X_in_A_scaled, X_target_A_scaled, test_size=0.3, random_state=42\n",
        ")\n",
        "X_val_in, X_test_in, X_val_tgt, X_test_tgt = train_test_split(\n",
        "    X_temp_in, X_temp_tgt, test_size=0.5, random_state=42\n",
        ")\n",
        "\n",
        "print(\"Treino A:\", X_train_in.shape,\n",
        "      \"Val A:\", X_val_in.shape,\n",
        "      \"Teste A:\", X_test_in.shape)\n",
        "\n",
        "# =========================================================\n",
        "# 5. Definir e treinar o AE (apenas usando conjunto A)\n",
        "# =========================================================\n",
        "\n",
        "input_shape = X_train_in.shape[1:]  # (n_wn_cut, 1)\n",
        "\n",
        "def build_conv_autoencoder(input_shape):\n",
        "    inp = layers.Input(shape=input_shape)\n",
        "    x = layers.Conv1D(16, kernel_size=10, strides=2,\n",
        "                      padding=\"same\", activation=\"relu\")(inp)\n",
        "    x = layers.Conv1D(32, kernel_size=10, strides=3,\n",
        "                      padding=\"same\", activation=\"relu\")(x)\n",
        "    x = layers.Conv1D(64, kernel_size=10, strides=3,\n",
        "                      padding=\"same\", activation=\"relu\")(x)\n",
        "    encoded = x\n",
        "    x = layers.Conv1DTranspose(64, kernel_size=10, strides=3,\n",
        "                               padding=\"same\", activation=\"relu\")(encoded)\n",
        "    x = layers.Conv1DTranspose(32, kernel_size=10, strides=3,\n",
        "                               padding=\"same\", activation=\"relu\")(x)\n",
        "    x = layers.Conv1DTranspose(16, kernel_size=10, strides=2,\n",
        "                               padding=\"same\", activation=\"relu\")(x)\n",
        "    x = layers.Conv1DTranspose(1, kernel_size=10, strides=1,\n",
        "                               padding=\"same\", activation=None)(x)\n",
        "    x = layers.Cropping1D(cropping=(0, max(0, x.shape[1] - input_shape[0])))(x)\n",
        "    if x.shape[1] < input_shape[0]:\n",
        "        pad = input_shape[0] - x.shape[1]\n",
        "        x = layers.ZeroPadding1D(padding=(0, pad))(x)\n",
        "    out = x\n",
        "    model = models.Model(inp, out, name=\"conv_AE_FTIR\")\n",
        "    return model\n",
        "\n",
        "autoencoder = build_conv_autoencoder(input_shape)\n",
        "autoencoder.summary()\n",
        "\n",
        "autoencoder.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "    loss=\"mse\"\n",
        ")\n",
        "\n",
        "early_stop = callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    patience=20,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "history = autoencoder.fit(\n",
        "    X_train_in, X_train_tgt,\n",
        "    validation_data=(X_val_in, X_val_tgt),\n",
        "    epochs=500,\n",
        "    batch_size=30,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# =========================================================\n",
        "# 6. Aplicar AE ao conjunto A (para comparar com padrão)\n",
        "# =========================================================\n",
        "\n",
        "X_in_A_scaled_all = ((X_cut_A - mean_in) / std_in)[..., np.newaxis]\n",
        "X_AE_A_scaled = autoencoder.predict(X_in_A_scaled_all)\n",
        "X_AE_A_scaled = X_AE_A_scaled[..., 0]\n",
        "\n",
        "X_AE_A = X_AE_A_scaled * std_tgt + mean_tgt   # saída AE na escala do alvo (SNV)\n",
        "\n",
        "# =========================================================\n",
        "# 7. Aplicar AE ao conjunto B (apenas recorte + AE, sem padrão clássico)\n",
        "# =========================================================\n",
        "\n",
        "# Recorta B para 1800–400 cm-1\n",
        "_, X_cut_B = cut_region(wavenumbers_full, X_raw_B,\n",
        "                        wn_min=400, wn_max=1800)\n",
        "\n",
        "# Usa a mesma normalização da entrada de A\n",
        "X_in_B_scaled = (X_cut_B - mean_in) / std_in\n",
        "X_in_B_scaled = X_in_B_scaled[..., np.newaxis]\n",
        "\n",
        "X_AE_B_scaled = autoencoder.predict(X_in_B_scaled)\n",
        "X_AE_B_scaled = X_AE_B_scaled[..., 0]\n",
        "X_AE_B = X_AE_B_scaled * std_tgt + mean_tgt  # mesma escala SNV das saídas de A\n",
        "\n",
        "# =========================================================\n",
        "# 8. Visualização em alguns exemplos de A\n",
        "# =========================================================\n",
        "\n",
        "def plot_before_after_A(idx_local, title_prefix=\"Exemplo A\"):\n",
        "    spec_in = X_cut_A[idx_local, :]\n",
        "    spec_std = X_target_A[idx_local, :]\n",
        "    spec_ae = X_AE_A[idx_local, :]\n",
        "    lab = labels_A[idx_local]\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.plot(wn_cut, spec_in, label=\"Bruto (cortado)\", alpha=0.6)\n",
        "    plt.plot(wn_cut, spec_std, label=\"Padrão (SG+ASL+SNV)\", alpha=0.8)\n",
        "    plt.plot(wn_cut, spec_ae, label=\"AE (saída)\", alpha=0.8)\n",
        "    plt.xlabel(\"Número de onda (cm$^{-1}$)\")\n",
        "    plt.ylabel(\"Intensidade\")\n",
        "    plt.title(f\"{title_prefix} idx_local={idx_local}, classe={lab}\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "np.random.seed(42)\n",
        "idx_rand_A = np.random.choice(X_cut_A.shape[0], size=min(5, X_cut_A.shape[0]), replace=False)\n",
        "for i in idx_rand_A:\n",
        "    plot_before_after_A(i)\n",
        "\n",
        "# =========================================================\n",
        "# 9. Salvar resultados\n",
        "# =========================================================\n",
        "\n",
        "# Crie o cabeçalho para os arquivos de dados\n",
        "header_for_data_files = ['Classe'] + list(wn_cut)\n",
        "\n",
        "# Conjunto A: padrão ouro + AE\n",
        "df_A_padr = pd.DataFrame(np.column_stack([labels_A, X_target_A]))\n",
        "df_A_padr.columns = header_for_data_files # Define o cabeçalho\n",
        "df_A_padr.to_csv(\"A_padroes.csv\", index=False, header=True)\n",
        "\n",
        "df_A_AE = pd.DataFrame(np.column_stack([labels_A, X_AE_A]))\n",
        "df_A_AE.columns = header_for_data_files # Define o cabeçalho\n",
        "df_A_AE.to_csv(\"A_AE.csv\", index=False, header=True)\n",
        "\n",
        "# Conjunto B: apenas AE\n",
        "df_B_AE = pd.DataFrame(np.column_stack([labels_B, X_AE_B]))\n",
        "df_B_AE.columns = header_for_data_files # Define o cabeçalho\n",
        "df_B_AE.to_csv(\"B_AE.csv\", index=False, header=True)\n",
        "\n",
        "# Wavenumbers (cortados)\n",
        "pd.DataFrame(wn_cut).T.to_csv(\"wavenumbers_cut.csv\", index=False, header=False)\n",
        "\n",
        "print(\"Arquivos salvos:\")\n",
        "print(\"  A_padroes.csv   -> padrão ouro (pipeline clássico) para conjunto A com números de onda no cabeçalho\")\n",
        "print(\"  A_AE.csv        -> saída do AE para conjunto A com números de onda no cabeçalho\")\n",
        "print(\"  B_AE.csv        -> saída do AE para conjunto B (aplicação automática) com números de onda no cabeçalho\")\n",
        "print(\"  wavenumbers_cut.csv -> eixos espectrais 400–1800 cm-1\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_data = pd.DataFrame({'wavenumber': wn_cut})\n",
        "\n",
        "for i, idx_local in enumerate(idx_rand_A):\n",
        "    spec_in = X_cut_A[idx_local, :]\n",
        "    spec_std = X_target_A[idx_local, :]\n",
        "    spec_ae = X_AE_A[idx_local, :]\n",
        "    lab = labels_A[idx_local]\n",
        "\n",
        "    combined_data[f'label_example_{i+1}'] = lab\n",
        "    combined_data[f'raw_cut_example_{i+1}'] = spec_in\n",
        "    combined_data[f'standard_example_{i+1}'] = spec_std\n",
        "    combined_data[f'ae_output_example_{i+1}'] = spec_ae\n",
        "\n",
        "# Save to CSV\n",
        "output_csv_path = \"comparison_examples.csv\"\n",
        "combined_data.to_csv(output_csv_path, index=False)\n",
        "\n",
        "print(f\"Dados dos 5 exemplos salvos em '{output_csv_path}'\")"
      ],
      "metadata": {
        "id": "XC94vlOL2qHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0497215a"
      },
      "source": [
        "original_indices_for_random_A = idx_A[idx_rand_A]\n",
        "\n",
        "X_raw_selected_full = X_raw_full[original_indices_for_random_A, :]\n",
        "labels_selected_full = labels_all[original_indices_for_random_A]\n",
        "\n",
        "combined_raw_full_data = pd.DataFrame({'wavenumber_full': wavenumbers_full})\n",
        "\n",
        "for i, lab in enumerate(labels_selected_full):\n",
        "    combined_raw_full_data[f'label_example_{i+1}'] = lab\n",
        "    combined_raw_full_data[f'raw_full_example_{i+1}'] = X_raw_selected_full[i, :]\n",
        "\n",
        "output_csv_path_raw_full = \"comparison_raw_full_examples.csv\"\n",
        "combined_raw_full_data.to_csv(output_csv_path_raw_full, index=False)\n",
        "\n",
        "print(f\"Dados dos 5 exemplos brutos completos salvos em '{output_csv_path_raw_full}'\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3d8ebfd"
      },
      "source": [
        "1. Dividir em dois subconjuntos: A (treino) e B (aplicação)\n",
        "\n",
        "Os dados brutos são divididos em dois subconjuntos: 'A' e 'B'.\n",
        "\n",
        "*   **Conjunto A (70%)**: Será usado para treinar o Autoencoder. Dentro deste conjunto, uma parte será processada pelo método clássico para servir de 'padrão ouro' para o AE.\n",
        "*   **Conjunto B (30%)**: Simula dados novos/desconhecidos, onde o Autoencoder treinado será aplicado para realizar o pré-processamento de forma automática e rápida, sem a necessidade de aplicar o pipeline clássico.\n",
        "\n",
        "2. Salvar resultados\n",
        "\n",
        "Finalmente, os resultados são salvos em arquivos CSV:\n",
        "\n",
        "*   `A_padroes.csv`: Contém os rótulos e os espectros do conjunto A processados pelo pipeline clássico (o padrão ouro).\n",
        "*   `A_AE.csv`: Contém os rótulos e os espectros do conjunto A processados pelo Autoencoder.\n",
        "*   `B_AE.csv`: Contém os rótulos e os espectros do conjunto B processados pelo Autoencoder.\n",
        "*   `wavenumbers_cut.csv`: Salva os números de onda correspondentes aos espectros cortados.\n",
        "*   `comparison_examples.csv`: Salva os dados utilizados nos exemplos (com corte espectral no raw).\n",
        "*   `comparison_raw_full_examples.csv`: : Salva os dados utilizados nos exemplos (sem corte espectral no raw).\n",
        "\n",
        "#==============================================================================\n",
        "\n",
        "1. Split into two subsets: A (training) and B (application)\n",
        "\n",
        "The raw data is divided into two subsets: 'A' and 'B'.\n",
        "\n",
        "- **Subset A (70%)**: Will be used to train the Autoencoder. Within this subset, a portion will be processed using the classical method to serve as a \"gold standard\" for the AE.\n",
        "- **Subset B (30%)**: Simulates new/unseen data, where the trained Autoencoder will be applied to perform preprocessing automatically and quickly, without the need to run the classical pipeline.\n",
        "\n",
        "2. Save results\n",
        "\n",
        "Finally, the results are saved as CSV files:\n",
        "\n",
        "- `A_patterns.csv`: Contains the labels and spectra of subset A processed by the classical pipeline (the gold standard).\n",
        "- `A_AE.csv`: Contains the labels and spectra of subset A processed by the Autoencoder.\n",
        "- `B_AE.csv`: Contains the labels and spectra of subset B processed by the Autoencoder.\n",
        "- `wavenumbers_cut.csv`: Saves the wavenumbers corresponding to the cut spectra.\n",
        "- `comparison_examples.csv`: Saves the data used in the examples (with spectral cut on the raw data).\n",
        "- `comparison_raw_full_examples.csv`: Saves the data used in the examples (without spectral cut on the raw data).\n"
      ]
    }
  ]
}