{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOTQ+J4jufMPE4A3l1pkNIk"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ===== Pacotes / Packages =====\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Fixar seed para reprodutibilidade / Fix seed for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "gYihXeEANhyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Carregar dados .xlsx / Load data .xlsx =====\n",
        "df = pd.read_excel(\"NAME.xlsx\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "UEdbKqbmNm3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Carregar dados .csv / Load data .csv =====\n",
        "df = pd.read_csv(\"NAME.csv\", sep=',') # especifica o separador / specifies the separator\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "7ID1osChvNPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separar features (X) e target (y) / Separate features (X) and target (y)\n",
        "X = df.iloc[:, 1:].values   # todas as colunas menos a primeira / all columns except the first\n",
        "y = df.iloc[:, 0].values    # apenas a primeira coluna / just the first column\n",
        "\n",
        "# Se 'y' contiver strings, codificar os rótulos / If 'y' contains strings, encode the labels\n",
        "if y.dtype == 'object': # ou use isinstance(y[0], str) se preferir verificar um elemento / or use isinstance(y[0], str) if you prefer to check one element\n",
        "    label_encoder = LabelEncoder()\n",
        "    y_encoded = label_encoder.fit_transform(y)\n",
        "else:\n",
        "    y_encoded = y\n",
        "\n",
        "# Transformar y em categorias (one-hot encoding) / Transform y into categories (one-hot encoding)\n",
        "# Use y_encoded para one-hot encoding / Use y_encoded for one-hot encoding\n",
        "y_cat = to_categorical(y_encoded)\n",
        "\n",
        "# Dividir em treino e teste / Split into training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_cat, test_size=0.2, random_state=42, stratify=y_encoded # stratify com y_encoded\n",
        ")\n",
        "\n",
        "# Normalizar dados / Normalize data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "utATycwvNsXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation of parameters / avaliação de parametros.\n",
        "\n",
        "# Reshape data for LSTM / Redimensionar dados para LSTM\n",
        "X_train_reshaped = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test_reshaped = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "# List of recurrent unit counts to test\n",
        "recurrent_unit_counts = [32, 64, 128] # Example: Test models with 32, 64, and 128 LSTM units\n",
        "\n",
        "val_losses = []\n",
        "test_losses = []\n",
        "test_accuracies = []\n",
        "\n",
        "# Keep the number of LSTM layers fixed to 1 for this evaluation\n",
        "num_fixed_layers = 1\n",
        "\n",
        "for num_recurrent_units in recurrent_unit_counts:\n",
        "    print(f\"\\nTraining model with {num_recurrent_units} LSTM units (in {num_fixed_layers} layer(s))\")\n",
        "\n",
        "    # Define model with varying number of LSTM units\n",
        "    model_current = Sequential([\n",
        "        LSTM(num_recurrent_units, input_shape=(X_train_reshaped.shape[1], 1)), # Single LSTM layer\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(y_cat.shape[1], activation=\"softmax\")\n",
        "    ])\n",
        "\n",
        "    # Compile model\n",
        "    model_current.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "    # EarlyStopping\n",
        "    early_stop_current = EarlyStopping(\n",
        "        monitor=\"val_loss\",\n",
        "        patience=5,\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "\n",
        "    # Train model using reshaped data for LSTM\n",
        "    history_current = model_current.fit(\n",
        "        X_train_reshaped, y_train,\n",
        "        validation_split=0.2,\n",
        "        epochs=50,\n",
        "        batch_size=16,\n",
        "        verbose=0, # Set verbose to 0 to avoid cluttering output during hyperparameter search\n",
        "        callbacks=[early_stop_current]\n",
        "    )\n",
        "\n",
        "    # Evaluate model on test set using reshaped data\n",
        "    loss_current, acc_current = model_current.evaluate(X_test_reshaped, y_test, verbose=0)\n",
        "    print(f\"Model with {num_recurrent_units} LSTM units - Test accuracy: {acc_current:.4f}, Test loss: {loss_current:.4f}\")\n",
        "\n",
        "    # Store the minimum validation loss achieved during training for plotting\n",
        "    val_losses.append(min(history_current.history['val_loss']))\n",
        "    test_losses.append(loss_current)\n",
        "    test_accuracies.append(acc_current)\n",
        "\n",
        "# Plotting the results\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(recurrent_unit_counts, val_losses, marker='o', label='Validation Loss')\n",
        "plt.plot(recurrent_unit_counts, test_losses, marker='x', label='Test Loss')\n",
        "plt.title('Loss vs. Number of Recurrent Units')\n",
        "plt.xlabel('Number of Recurrent Units')\n",
        "plt.ylabel('Loss')\n",
        "plt.xticks(recurrent_unit_counts) # Ensure x-ticks correspond to the unit counts\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Find the best scenario\n",
        "# Using test loss to determine the best model configuration\n",
        "best_index = np.argmin(test_losses)\n",
        "best_num_recurrent_units = recurrent_unit_counts[best_index]\n",
        "best_test_loss = test_losses[best_index]\n",
        "best_test_accuracy = test_accuracies[best_index]\n",
        "best_val_loss = val_losses[best_index]\n",
        "\n",
        "print(f\"\\nBest Scenario:\")\n",
        "print(f\"Number of Recurrent Units: {best_num_recurrent_units}\")\n",
        "print(f\"Corresponding Validation Loss (min): {best_val_loss:.4f}\")\n",
        "print(f\"Corresponding Test Loss: {best_test_loss:.4f}\")\n",
        "print(f\"Corresponding Test Accuracy: {best_test_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "VYIRSXxUgeLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation of parameters / avaliação de parametros.\n",
        "\n",
        "# Reshape data for LSTM / Redimensionar dados para LSTM\n",
        "# Ensure X_train_reshaped and X_test_reshaped are available\n",
        "if 'X_train_reshaped' not in globals():\n",
        "    X_train_reshaped = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "    X_test_reshaped = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "# Fixed number of recurrent units and layers based on user's request\n",
        "fixed_num_recurrent_units = 32\n",
        "fixed_num_recurrent_layers = 1 # As per the new request\n",
        "\n",
        "# List of Dense layer counts to test\n",
        "dense_layer_counts = [1, 2, 3, 4] # Example range: 1, 2, 3, or 4 Dense layers (excluding the output layer)\n",
        "\n",
        "val_losses = []\n",
        "test_losses = []\n",
        "test_accuracies = []\n",
        "\n",
        "for num_dense_layers in dense_layer_counts:\n",
        "    print(f\"\\nTraining model with {fixed_num_recurrent_layers} LSTM layer(s) ({fixed_num_recurrent_units} units) and {num_dense_layers} Dense layer(s)\")\n",
        "\n",
        "    model_current = Sequential()\n",
        "\n",
        "    # Add fixed number of LSTM layers\n",
        "    for i in range(fixed_num_recurrent_layers):\n",
        "        if i == 0:\n",
        "            model_current.add(LSTM(fixed_num_recurrent_units, input_shape=(X_train_reshaped.shape[1], 1), return_sequences=(fixed_num_recurrent_layers > 1)))\n",
        "        elif i < fixed_num_recurrent_layers - 1:\n",
        "            model_current.add(LSTM(fixed_num_recurrent_units, return_sequences=True))\n",
        "        else:\n",
        "            model_current.add(LSTM(fixed_num_recurrent_units))\n",
        "\n",
        "    # Add varying number of Dense layers\n",
        "    for _ in range(num_dense_layers):\n",
        "        model_current.add(Dense(32, activation='relu'))\n",
        "\n",
        "    # Add the final output layer\n",
        "    model_current.add(Dense(y_cat.shape[1], activation=\"softmax\"))\n",
        "\n",
        "    model_current.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "    early_stop_current = EarlyStopping(\n",
        "        monitor=\"val_loss\",\n",
        "        patience=5,\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "\n",
        "    history_current = model_current.fit(\n",
        "        X_train_reshaped, y_train,\n",
        "        validation_split=0.2,\n",
        "        epochs=50,\n",
        "        batch_size=16,\n",
        "        verbose=0,\n",
        "        callbacks=[early_stop_current]\n",
        "    )\n",
        "\n",
        "    loss_current, acc_current = model_current.evaluate(X_test_reshaped, y_test, verbose=0)\n",
        "    print(f\"Model with {num_dense_layers} Dense layers - Test accuracy: {acc_current:.4f}, Test loss: {loss_current:.4f}\")\n",
        "\n",
        "    val_losses.append(min(history_current.history['val_loss']))\n",
        "    test_losses.append(loss_current)\n",
        "    test_accuracies.append(acc_current)\n",
        "\n",
        "# Plotting the results\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(dense_layer_counts, val_losses, marker='o', label='Validation Loss')\n",
        "plt.plot(dense_layer_counts, test_losses, marker='x', label='Test Loss')\n",
        "plt.title(f'Loss vs. Number of Dense Layers (Fixed LSTM Units = {fixed_num_recurrent_units}, Fixed LSTM Layers = {fixed_num_recurrent_layers})')\n",
        "plt.xlabel('Number of Dense Layers')\n",
        "plt.ylabel('Loss')\n",
        "plt.xticks(dense_layer_counts)\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "best_index = np.argmin(test_losses)\n",
        "best_num_dense_layers = dense_layer_counts[best_index]\n",
        "best_test_loss = test_losses[best_index]\n",
        "best_test_accuracy = test_accuracies[best_index]\n",
        "best_val_loss = val_losses[best_index]\n",
        "\n",
        "print(f\"\\nBest Scenario:\")\n",
        "print(f\"Number of Dense Layers: {best_num_dense_layers}\")\n",
        "print(f\"Fixed Number of Recurrent Units: {fixed_num_recurrent_units}\")\n",
        "print(f\"Fixed Number of Recurrent Layers: {fixed_num_recurrent_layers}\")\n",
        "print(f\"Corresponding Validation Loss (min): {best_val_loss:.4f}\")\n",
        "print(f\"Corresponding Test Loss: {best_test_loss:.4f}\")\n",
        "print(f\"Corresponding Test Accuracy: {best_test_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "EbbltYbUjAhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Definir modelo RNN / Define RNN Model =====\n",
        "\n",
        "if 'X_train_reshaped' not in locals():\n",
        "    X_train_reshaped = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "\n",
        "model = Sequential([\n",
        "    LSTM(32, input_shape=(X_train_reshaped.shape[1], 1)), # LSTM layer\n",
        "    Dense(32, activation='relu'), # Dense layer\n",
        "    Dense(y_cat.shape[1], activation=\"softmax\") # Output layer\n",
        "])\n"
      ],
      "metadata": {
        "id": "V37VbTdcOBkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compilar modelo / compile model\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# EarlyStopping\n",
        "early_stop = EarlyStopping(\n",
        "    monitor=\"val_loss\",       # monitora o erro de validação / monitors the validation error\n",
        "    patience=5,               # quantas épocas sem melhora antes de parar / how many epochs without improvement before stopping\n",
        "    restore_best_weights=True # garante que volte para a melhor época / ensures that it returns to the best season\n",
        ")\n",
        "\n",
        "# Treinar modelo / Train model\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=50,\n",
        "    batch_size=16,\n",
        "    verbose=1,\n",
        "    callbacks=[early_stop]\n",
        ")\n",
        "\n",
        "# Avaliar modelo / Evaluate model\n",
        "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test accuracy: {acc:.4f}\")\n",
        "\n",
        "# Melhor época\n",
        "melhor_ep = np.argmin(history.history[\"val_loss\"]) + 1\n",
        "melhor_val = history.history[\"val_loss\"][melhor_ep - 1]\n",
        "print(f\"Best epoch chosen by EarlyStopping: {melhor_ep} (val_loss = {melhor_val:.4f})\")\n"
      ],
      "metadata": {
        "id": "GowopTW5ODeN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Plotar curvas de Loss e Acurácia / Plot Loss and Accuracy Curves =====\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EQiOEQWPoZ4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Matriz de confusão / Confusion matrix =====\n",
        "# Previsões / Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Matriz / Matrix\n",
        "cm = confusion_matrix(y_true, y_pred_classes)\n",
        "\n",
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=np.unique(y),\n",
        "            yticklabels=np.unique(y))\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion matrix\")\n",
        "plt.show()\n",
        "\n",
        "# ===== Relatório de classificação / classification report =====\n",
        "print(\"Classification report:\\n\")\n",
        "print(classification_report(y_true, y_pred_classes, target_names=[f\"Class {c}\" for c in np.unique(y)]))"
      ],
      "metadata": {
        "id": "jBeDOpXiOHNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use curvas individuais (multiclass ROC) quando quiser analisar o desempenho do modelo em cada classe separadamente. / Use curvas individuais (ROC multiclasse) quando quiser analisar o desempenho do modelo em cada classe separadamente.\n",
        "\n",
        "# Fit LabelEncoder to the original unique classes / Ajustar LabelEncoder às classes originais exclusivas\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(np.unique(y))\n",
        "\n",
        "# Compute ROC curve and ROC area for each class / Calcular a curva ROC e a área ROC para cada classe\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "\n",
        "unique_classes = np.unique(y)  # Use original unique classes for labeling / Use classes originais exclusivas para rotulagem\n",
        "n_classes = len(unique_classes)\n",
        "\n",
        "for i in range(n_classes):\n",
        "    class_value = unique_classes[i]\n",
        "    # Use label_encoder to get the correct index for the current class / Use label_encoder para obter o índice correto para a classe atual\n",
        "    class_index = label_encoder.transform([class_value])[0]\n",
        "\n",
        "    # Check if the current class is present in the test set / Verifique se a classe atual está presente no conjunto de teste\n",
        "    if np.sum(y_test[:, class_index]) > 0:\n",
        "        fpr[i], tpr[i], _ = roc_curve(y_test[:, class_index], y_pred[:, class_index])\n",
        "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "    else:\n",
        "        # If a class is not in the test set, set AUC to NaN and skip plotting its curve / Se uma classe não estiver no conjunto de teste, defina AUC como NaN e pule a plotagem de sua curva\n",
        "        roc_auc[i] = np.nan\n",
        "        print(f\"Warning: Class {class_value} has no positive samples in the test set. Skipping ROC curve for this class.\")\n",
        "\n",
        "\n",
        "# Plot ROC curves / Traçar curvas ROC\n",
        "plt.figure(figsize=(8, 6))\n",
        "colors = ['blue', 'red', 'green', 'orange', 'purple', 'brown', 'pink', 'gray', 'olive', 'cyan']\n",
        "for i in range(n_classes):\n",
        "    # Only plot if the AUC was calculated (class was in the test set) / Somente plote se a AUC foi calculada (a classe estava no conjunto de teste)\n",
        "    if not np.isnan(roc_auc[i]):\n",
        "        # Ensure there are enough colors / Certifique-se de que há cores suficientes\n",
        "        color = colors[i % len(colors)]\n",
        "        plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
        "                 label='ROC curve of class {0} (area = {1:0.2f})'.format(unique_classes[i], roc_auc[i]))\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
        "plt.xlim([-0.05, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Multiclass ROC Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4W2i1MeWOrZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25613d59"
      },
      "source": [
        "# Use macro-average ROC quando quiser uma visão geral do desempenho do modelo em todas as classes, sem considerar desequilíbrio entre elas. / Use ROC macro-médio quando quiser uma visão geral do desempenho do modelo em todas as classes, sem considerar desequilíbrio entre elas.\n",
        "\n",
        "# Calculate macro-average ROC curve and AUC / Calcular a curva ROC macromédia e a AUC\n",
        "# First aggregate all false positive rates / Primeiro, agregue todas as taxas de falsos positivos\n",
        "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes) if not np.isnan(roc_auc[i])]))\n",
        "\n",
        "# Then interpolate all ROC curves at this points / Em seguida, interpole todas as curvas ROC nesses pontos\n",
        "mean_tpr = np.zeros_like(all_fpr)\n",
        "for i in range(n_classes):\n",
        "    if not np.isnan(roc_auc[i]):\n",
        "        mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
        "\n",
        "# Average it and compute AUC / Calcule a média e a AUC\n",
        "mean_tpr /= sum([not np.isnan(roc_auc[i]) for i in range(n_classes)]) # Divide by the number of classes that were in the test set/ Divida pelo número de classes que estavam no conjunto de teste\n",
        "\n",
        "macro_roc_auc = auc(all_fpr, mean_tpr)\n",
        "\n",
        "# Plot macro-average ROC curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(all_fpr, mean_tpr, color='red', linestyle='-', linewidth=2,\n",
        "         label='Macro-average ROC curve (area = {0:0.2f})'.format(macro_roc_auc))\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
        "plt.xlim([-0.05, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Multiclass ROC Curve (Macro-average)')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}