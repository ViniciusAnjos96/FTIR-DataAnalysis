{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPMWYjxAnObmwoSEwuHNEtw"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ===== Pacotes / Packages =====\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.svm import SVC, SVR\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, classification_report, r2_score, roc_curve, auc, mean_squared_error\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.inspection import DecisionBoundaryDisplay"
      ],
      "metadata": {
        "id": "oNaSbZz7XQHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVM (Classification)"
      ],
      "metadata": {
        "id": "xyMSvD2ePGZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 1. Ler os dados .XLSX / Read .XLSX data =====\n",
        "dados = pd.read_excel(\"NAME.xlsx\")\n",
        "print(dados.head())"
      ],
      "metadata": {
        "id": "HWdHPjmFuKeQ",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Ler os dados .CSV / Read .CSV data ===\n",
        "dados = pd.read_csv('NAME.csv', sep=',')  # especifica o separador / specifies the separator\n",
        "print(dados.head())"
      ],
      "metadata": {
        "id": "w7ulRSNOuQPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 2. Garantir que preditoras sejam numéricas / Ensure predictors are numeric =====\n",
        "X = dados.drop(dados.columns[0], axis=1).apply(pd.to_numeric)\n",
        "y = dados[dados.columns[0]].values.ravel()  # Classe na primeira coluna / Class in first column\n",
        "\n",
        "# ===== 3. Padronizar os dados / Standardize data =====\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# ===== Exclui NaN / Excludes NaN =====\n",
        "dados_cleaned = dados.dropna()"
      ],
      "metadata": {
        "id": "R9GvD8-iXSR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 4. Divisão treino/teste / Training/testing division =====\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.20, random_state=1234, stratify=y\n",
        ")\n",
        "\n",
        "print(\"Train:\", X_train.shape, y_train.shape)\n",
        "print(\"Test:\", X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "BeMsdrNXXUBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 5. Treinar SVM / Train SVM =====\n",
        "\n",
        "# Esse código utiliza a estratégia \"um grupo versus todos os demais\" (one-vs-rest) para a classificação multiclasse. Para fazer um grupo versus o outro (one-vs-one) acrescente: decision_function_shape='ovo'\n",
        "# This code uses the \"one group versus all others\" strategy for multiclass classification. To do one-vs-one classification add: decision_function_shape='ovo'\n",
        "\n",
        "modelo_svm = SVC(kernel=\"linear\", probability=True, random_state=1234) #testar com outros kernel / test with other kernels = linear, poly, rbf e sigmoid.\n",
        "modelo_svm.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "DnuFfcVGXWUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 6. Predição / Prediction =====\n",
        "y_pred_train = modelo_svm.predict(X_train)\n",
        "y_pred_test = modelo_svm.predict(X_test)\n",
        "\n",
        "print(\"Training Accuracy:\", accuracy_score(y_train, y_pred_train))\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred_test))"
      ],
      "metadata": {
        "id": "VK7tNyI3XYLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the number of support vectors / Número de vetores de suporte\n",
        "print(\"Number of support vectors:\", modelo_svm.support_vectors_.shape[0])"
      ],
      "metadata": {
        "id": "vbWH991uyo4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 7. Métricas / Metrics =====\n",
        "classes = sorted(np.unique(y))\n",
        "\n",
        "# Matriz de confusão / Confusion matrix\n",
        "conf_mat = confusion_matrix(y_test, y_pred_test, labels=classes)\n",
        "cm_df = pd.DataFrame(conf_mat, index=classes, columns=classes)\n",
        "\n",
        "# Visualização / Preview\n",
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel(\"Predict\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix - SVM\")\n",
        "plt.show()\n",
        "\n",
        "# Classification report\n",
        "print(\"\\nClassification Report Teste:\\n\")\n",
        "print(classification_report(y_test, y_pred_test, target_names=[str(c) for c in classes]))"
      ],
      "metadata": {
        "id": "y68O50_DhW1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 8. Validação Cruzada com K-Fold / K-Fold Cross-Validation =====\n",
        "\n",
        "# Validar o modelo SVM com validação cruzada (K=5 por padrão) / Validate the SVM model with cross-validation (K=5 by default)\n",
        "cv_scores = cross_val_score(modelo_svm, X_scaled, y, cv=5)\n",
        "\n",
        "print(\"Accuracies per Fold:\", cv_scores)\n",
        "print(\"Average Accuracy (K-Fold):\", np.mean(cv_scores))\n",
        "print(\"Standard Deviation of Accuracy (K-Fold):\", np.std(cv_scores))"
      ],
      "metadata": {
        "id": "7KjuVTcBNNdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 9. Feature Importance (para kernel linear) =====\n",
        "\n",
        "# Extrair os coeficientes do modelo (para kernel linear) / Extract model coefficients (for linear kernel)\n",
        "# Os coeficientes indicam a importância de cada feature na decisão de fronteira / The coefficients indicate the importance of each feature in the frontier decision\n",
        "coeficientes = modelo_svm.coef_[0]  # Pegando os coeficientes para a primeira classe (ajustar se necessário) / Getting the coefficients for the first class (adjust if necessary)\n",
        "\n",
        "# Obter os nomes das features / Get feature names\n",
        "nomes_features = X.columns\n",
        "\n",
        "# Criar um DataFrame para visualizar coeficientes e nomes das features / Create a DataFrame to visualize coefficients and feature names\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': nomes_features,\n",
        "    'importance': np.abs(coeficientes) # Usar valor absoluto para importância / Use absolute value for importance\n",
        "})\n",
        "\n",
        "# Ordenar as features por importância / Sort features by importance\n",
        "feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
        "\n",
        "# Visualizar as top N features (ex: top 10) / View the top N features (e.g. top 10)\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='importance', y='feature', data=feature_importance.head(20), palette='viridis')\n",
        "plt.title('Top 10 Features by Importance (Linear SVM Coefficients)')\n",
        "plt.xlabel('Importance (Absolute Coefficient Value)')\n",
        "plt.ylabel('Feature')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oZp_BSjt5NOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 10. Plot classification boundaries =====\n",
        "\n",
        "def plot_decision_boundary_multiclass(model, X, y, title=\"SVM Decision Boundary (PCA 2D)\"):\n",
        "    # Reduz para 2D com PCA / Reduce to 2D with PCA\n",
        "    pca = PCA(n_components=2)\n",
        "    X_2d = pca.fit_transform(X)\n",
        "\n",
        "    # Converter rótulos de classe para numéricos para o scatter plot / Convert class labels to numeric for scatter plot\n",
        "    y_numeric, classes = pd.factorize(y)\n",
        "\n",
        "    # Modelo auxiliar só para visualização / Auxiliary model for viewing only\n",
        "    viz_model = SVC(kernel=model.kernel, C=model.C, gamma=model.gamma, decision_function_shape='ovr')\n",
        "    viz_model.fit(X_2d, y_numeric) # Treinar o modelo auxiliar com rótulos numéricos / Train auxiliary model with numeric labels\n",
        "\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(6, 5))\n",
        "\n",
        "    # Fronteira de decisão (somente 'predict') / Decision boundary ('predict' only)\n",
        "    DecisionBoundaryDisplay.from_estimator(\n",
        "        viz_model,\n",
        "        X_2d,\n",
        "        response_method=\"predict\",\n",
        "        plot_method=\"pcolormesh\",\n",
        "        cmap=\"coolwarm\",\n",
        "        alpha=0.3,\n",
        "        ax=ax\n",
        "    )\n",
        "\n",
        "    # Pontos / Points\n",
        "    scatter = ax.scatter(X_2d[:, 0], X_2d[:, 1], c=y_numeric, s=30, edgecolors=\"k\", cmap=\"coolwarm\") # Usar y_numeric para colorir os pontos / Use y_numeric to color the points\n",
        "\n",
        "    # Vetores de suporte / Support vectors\n",
        "    if hasattr(viz_model, \"support_vectors_\"):\n",
        "        ax.scatter(\n",
        "            viz_model.support_vectors_[:, 0],\n",
        "            viz_model.support_vectors_[:, 1],\n",
        "            s=150,\n",
        "            facecolors=\"none\",\n",
        "            edgecolors=\"k\"\n",
        "        )\n",
        "\n",
        "    # Criar um mapeamento manual para a legenda com os rótulos originais / Create a manual mapping for the legend with original labels\n",
        "    handles, _ = scatter.legend_elements()\n",
        "    legend = ax.legend(handles, classes, loc=\"upper right\", title=\"Classes\")\n",
        "    ax.add_artist(legend)\n",
        "\n",
        "\n",
        "    ax.set_title(title)\n",
        "    plt.show()\n",
        "\n",
        "# Usar no seu modelo já treinado (com 9 features), mas reduzindo p/ PCA 2D só no gráfico / Use on your already trained model (with 9 features), but reducing to 2D PCA only on the graph\n",
        "plot_decision_boundary_multiclass(modelo_svm, X_scaled, y, \"SVM Decision Boundary (Multiclass, PCA 2D)\")"
      ],
      "metadata": {
        "id": "ep60Vbp2yPDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use curvas individuais (multiclass ROC) quando quiser analisar o desempenho do modelo em cada classe separadamente. / Use curvas individuais (ROC multiclasse) quando quiser analisar o desempenho do modelo em cada classe separadamente.\n",
        "\n",
        "# Fit LabelEncoder to the original unique classes / Ajustar LabelEncoder às classes originais exclusivas\n",
        "label_encoder = LabelEncoder()\n",
        "y_test_encoded = label_encoder.fit_transform(y_test)\n",
        "y_pred_test_encoded = label_encoder.transform(y_pred_test)\n",
        "\n",
        "\n",
        "# Compute ROC curve and ROC area for each class / Calcular a curva ROC e a área ROC para cada classe\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "\n",
        "unique_classes = label_encoder.classes_ # Use the classes from the fitted encoder / Use as classes do codificador ajustado\n",
        "n_classes = len(unique_classes)\n",
        "\n",
        "for i in range(n_classes):\n",
        "    class_value = unique_classes[i]\n",
        "\n",
        "    # Create binary true and predicted labels for the current class (one-vs-rest)\n",
        "    y_test_binary = (y_test_encoded == i).astype(int)\n",
        "    y_pred_test_binary = (y_pred_test_encoded == i).astype(int)\n",
        "\n",
        "    # Check if the current class is present in the test set (has positive samples)\n",
        "    if np.sum(y_test_binary) > 0:\n",
        "        fpr[i], tpr[i], _ = roc_curve(y_test_binary, y_pred_test_binary)\n",
        "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "    else:\n",
        "        # If a class is not in the test set, set AUC to NaN and skip plotting its curve\n",
        "        roc_auc[i] = np.nan\n",
        "        print(f\"Warning: Class {class_value} has no positive samples in the test set. Skipping ROC curve for this class.\")\n",
        "\n",
        "\n",
        "# Plot ROC curves / Traçar curvas ROC\n",
        "plt.figure(figsize=(8, 6))\n",
        "colors = ['blue', 'red', 'green', 'orange', 'purple', 'brown', 'pink', 'gray', 'olive', 'cyan']\n",
        "for i in range(n_classes):\n",
        "    # Only plot if the AUC was calculated (class was in the test set) / Somente plote se a AUC foi calculada (a classe estava no conjunto de teste)\n",
        "    if not np.isnan(roc_auc[i]):\n",
        "        # Ensure there are enough colors / Certifique-se de que há cores suficientes\n",
        "        color = colors[i % len(colors)]\n",
        "        plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
        "                 label='ROC curve of class {0} (area = {1:0.2f})'.format(unique_classes[i], roc_auc[i]))\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
        "plt.xlim([-0.05, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Multiclass ROC Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RxByCHSvxp3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use macro-average ROC quando quiser uma visão geral do desempenho do modelo em todas as classes, sem considerar desequilíbrio entre elas. / Use ROC macro-médio quando quiser uma visão geral do desempenho do modelo em todas as classes, sem considerar desequilíbrio entre elas.\n",
        "\n",
        "# Calculate macro-average ROC curve and AUC / Calcular a curva ROC macromédia e a AUC\n",
        "# First aggregate all false positive rates / Primeiro, agregue todas as taxas de falsos positivos\n",
        "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes) if not np.isnan(roc_auc[i])]))\n",
        "\n",
        "# Then interpolate all ROC curves at this points / Em seguida, interpole todas as curvas ROC nesses pontos\n",
        "mean_tpr = np.zeros_like(all_fpr)\n",
        "for i in range(n_classes):\n",
        "    if not np.isnan(roc_auc[i]):\n",
        "        mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
        "\n",
        "# Average it and compute AUC / Calcule a média e a AUC\n",
        "mean_tpr /= sum([not np.isnan(roc_auc[i]) for i in range(n_classes)]) # Divide by the number of classes that were in the test set/ Divida pelo número de classes que estavam no conjunto de teste\n",
        "\n",
        "macro_roc_auc = auc(all_fpr, mean_tpr)\n",
        "\n",
        "# Plot macro-average ROC curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(all_fpr, mean_tpr, color='red', linestyle='-', linewidth=2,\n",
        "         label='Macro-average ROC curve (area = {0:0.2f})'.format(macro_roc_auc))\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
        "plt.xlim([-0.05, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Multiclass ROC Curve (Macro-average)')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_7BTmy66yQaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVR (Regression)"
      ],
      "metadata": {
        "id": "kJI2MGLePNwn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Com lables / with labels"
      ],
      "metadata": {
        "id": "wLZAvMBdPoFa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Excel file / Carregar o arquivo xlsx.\n",
        "df = pd.read_excel('NAME.xlsx')\n",
        "\n",
        "# Exclude the first column (labels) / Exclua a primeira coluna (rótulos)\n",
        "df_processed = df.iloc[:, 1:]\n",
        "\n",
        "print(\"DataFrame after excluding the first column:\")\n",
        "display(df_processed.head())"
      ],
      "metadata": {
        "id": "kEaQQf4LQc9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CSV file / Carregar o arquivo CSV\n",
        "df = pd.read_csv('NAME.csv')\n",
        "\n",
        "# Exclude the first column (labels) / Exclua a primeira coluna (rótulos)\n",
        "df_processed = df.iloc[:, 1:]\n",
        "\n",
        "print(\"DataFrame after excluding the first column:\")\n",
        "display(df_processed.head())"
      ],
      "metadata": {
        "id": "dVeyDef5PSPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define target column by index. / Defina a coluna de destino por índice.\n",
        "target_column_index = 3\n",
        "\n",
        "# Select target (y) and features (X) based on the column index / Selecione o alvo (y) e as características (X) com base no índice da coluna.\n",
        "y = df_processed.iloc[:, target_column_index]\n",
        "X = df_processed.drop(df_processed.columns[target_column_index], axis=1)\n",
        "\n",
        "# Get the name of the target column / Obtenha o nome da coluna de destino.\n",
        "target_column_name = df_processed.columns[target_column_index]\n",
        "\n",
        "# Split the data into training and testing sets / Divida os dados em conjuntos de treinamento e teste.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the features (important for SVR) / # Scale the features (important for SVR) / Dimensionar as características (importante para SVR)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"Data preparation complete:\")\n",
        "print(f\"Target Column Name: {target_column_name}\")\n",
        "print(f\"X_train_scaled shape: {X_train_scaled.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"X_test_scaled shape: {X_test_scaled.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")"
      ],
      "metadata": {
        "id": "63MmqxhmPvPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize and train the SVR model / Inicialize e treine o modelo SVR.\n",
        "# Using a radial basis function kernel (rbf) is common for SVR. / O uso de um kernel de função de base radial (rbf) é comum em SVR.\n",
        "svr_model = SVR(kernel='rbf', C=100, epsilon=0.1)\n",
        "svr_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions on the scaled test set / Faça previsões no conjunto de teste escalonado.\n",
        "y_pred = svr_model.predict(X_test_scaled)"
      ],
      "metadata": {
        "id": "kpURSABhPy8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model /\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.scatterplot(x=y_test, y=y_pred)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
        "plt.xlabel('Actual Weight')\n",
        "plt.ylabel('Predicted Weight')\n",
        "plt.title('Actual vs. Predicted Weight (SVR Model)')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(\"SVR Model Evaluation:\")\n",
        "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
        "print(f\"R-squared (R2) Score: {r2:.2f}\")"
      ],
      "metadata": {
        "id": "3rXhFd5dP1EJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sem labels / no labels"
      ],
      "metadata": {
        "id": "McgmJVR-P4Yw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Excel file / Carregar o arquivo Excel\n",
        "df = pd.read_excel('NAME.xlsx')\n",
        "\n",
        "df = df.dropna()\n",
        "\n",
        "print(\"DataFrame:\")\n",
        "display(df.head())"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ZbJOcouPQkOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CSV file / Carregar o arquivo CSV\n",
        "df = pd.read_csv('NAME.csv')\n",
        "\n",
        "df = df.dropna()\n",
        "\n",
        "print(\"DataFrame:\")\n",
        "display(df.head())"
      ],
      "metadata": {
        "id": "-bfSEr85P5v8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define target column by index. / Defina a coluna de destino pelo índice.\n",
        "target_column_index = 1\n",
        "\n",
        "# Select target (y) and features (X) based on the column index / Selecione o alvo (y) e as características (X) com base no índice da coluna.\n",
        "y = df.iloc[:, target_column_index]\n",
        "X = df.drop(df.columns[target_column_index], axis=1)\n",
        "\n",
        "# Get the name of the target column / Obtenha o nome da coluna de destino.\n",
        "target_column_name = df.columns[target_column_index]\n",
        "\n",
        "# Split the data into training and testing sets / Divida os dados em conjuntos de treinamento e teste.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the features (important for SVR) / Dimensionar as características (importante para SVR)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"Data preparation complete:\")\n",
        "print(f\"Target Column Name: {target_column_name}\")\n",
        "print(f\"X_train_scaled shape: {X_train_scaled.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"X_test_scaled shape: {X_test_scaled.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")"
      ],
      "metadata": {
        "id": "OvTHFm_nP8RQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize and train the SVR model / Inicialize e treine o modelo SVR.\n",
        "# Using a radial basis function kernel (rbf) is common for SVR. / O uso de um kernel de função de base radial (rbf) é comum em SVR.\n",
        "svr_model = SVR(kernel='rbf', C=100, epsilon=0.1)\n",
        "svr_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions on the scaled test set / Faça previsões no conjunto de teste escalonado.\n",
        "y_pred = svr_model.predict(X_test_scaled)"
      ],
      "metadata": {
        "id": "0f2t1OL3P-Ko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model / Avalie o modelo\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.scatterplot(x=y_test, y=y_pred)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
        "plt.xlabel('Actual')\n",
        "plt.ylabel('Predicted')\n",
        "plt.title('Actual vs. Predicted (SVR Model)')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(\"SVR Model Evaluation:\")\n",
        "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
        "print(f\"R-squared (R2) Score: {r2:.2f}\")"
      ],
      "metadata": {
        "id": "n_KuAWl2P_92"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}