{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNRSI7GlSFepjdG+nXLI60P"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "source": [
        "# Kmeans+PCA\n",
        "# Change the NAME.csv\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import LabelEncoder # Import LabelEncoder\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('NAME.csv')\n",
        "\n",
        "# The first column is the class, the rest are the FTIR spectra data (wavenumbers)\n",
        "# We need to separate the features (spectra) from the labels (class)\n",
        "X = df.iloc[:, 1:] # All columns from the second one onwards\n",
        "y = df.iloc[:, 0]  # The first column is the class\n",
        "\n",
        "# Convert original string labels to numerical labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Apply K-means clustering\n",
        "# We expect 3 clusters based on the description\n",
        "kmeans = KMeans(n_clusters=3, random_state=42, n_init=10) # Added n_init to avoid future warnings\n",
        "kmeans.fit(X)\n",
        "\n",
        "# Get the cluster labels assigned by K-means\n",
        "cluster_labels = kmeans.labels_\n",
        "\n",
        "# You can now analyze the results.\n",
        "# One way is to see how the K-means clusters align with the original classes.\n",
        "# A contingency matrix can be useful for this.\n",
        "print(\"Confusion Matrix (Original Class vs K-means Cluster):\")\n",
        "# Use the encoded original labels for the confusion matrix\n",
        "print(confusion_matrix(y_encoded, cluster_labels))\n",
        "\n",
        "# Visualize the results (optional, requires dimensionality reduction like PCA)\n",
        "# To visualize high-dimensional data like spectra, we usually reduce its dimensions first.\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=cluster_labels, cmap='viridis', s=50, alpha=0.7)\n",
        "plt.title('K-means Clustering of FTIR Spectra (PCA Reduced)')\n",
        "plt.xlabel('PCA Component 1')\n",
        "plt.ylabel('PCA Component 2')\n",
        "plt.colorbar(scatter, label='K-means Cluster')\n",
        "\n",
        "# Optionally, plot the original classes alongside the clusters for comparison\n",
        "# plt.figure(figsize=(10, 6))\n",
        "# scatter_original = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y_encoded, cmap='viridis', s=50, alpha=0.7) # Use encoded labels here too\n",
        "# plt.title('Original Classes of FTIR Spectra (PCA Reduced)')\n",
        "# plt.xlabel('PCA Component 1')\n",
        "# plt.ylabel('PCA Component 2')\n",
        "# plt.colorbar(scatter_original, label='Original Class')\n",
        "\n",
        "plt.show()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "vhJgypMpzLpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classifiaction Report\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Generate the classification report using the original encoded labels and the predicted cluster labels\n",
        "# Since K-means is an unsupervised method, the cluster labels may not directly correspond to the original class labels.\n",
        "# We can use the classification report to see how well each original class is represented in the clusters.\n",
        "# Note: The report will treat clusters as if they are predicted classes. The 'accuracy' in this context\n",
        "# doesn't mean correct classification in the supervised sense, but rather the overall agreement\n",
        "# between the original labels and the cluster labels after potentially remapping clusters to classes.\n",
        "# For unsupervised learning, interpretation is more about finding structure in data.\n",
        "\n",
        "# To get a meaningful classification report, we might need to map clusters to classes based on the confusion matrix\n",
        "# For simplicity here, we'll generate the report directly, understanding its interpretation limitations\n",
        "# for unsupervised learning where cluster labels don't have inherent meaning before mapping.\n",
        "\n",
        "report = classification_report(y_encoded, cluster_labels, target_names=label_encoder.classes_, output_dict=True)\n",
        "\n",
        "# Convert the report dictionary to a pandas DataFrame for better visualization\n",
        "report_df = pd.DataFrame(report).transpose()\n",
        "\n",
        "# Drop the 'support' row as it's not needed for the table visualization\n",
        "# report_df = report_df.drop('support')\n",
        "\n",
        "# Calculate accuracy (this is the accuracy score from the report, which is the average recall for the clusters)\n",
        "# In unsupervised learning, this is often interpreted as a measure of agreement rather than prediction accuracy.\n",
        "accuracy = report_df.loc['accuracy', 'f1-score'] # f1-score column for accuracy row contains the overall accuracy\n",
        "\n",
        "# Visualize the classification report as a table using matplotlib\n",
        "fig, ax = plt.subplots(figsize=(10, report_df.shape[0] * 0.8)) # Adjust figure size as needed\n",
        "ax.axis('tight')\n",
        "ax.axis('off')\n",
        "\n",
        "# Create the table\n",
        "table = ax.table(cellText=report_df.values.round(2), # Round values for better readability\n",
        "                 colLabels=report_df.columns,\n",
        "                 rowLabels=report_df.index,\n",
        "                 cellLoc='center',\n",
        "                 loc='center')\n",
        "\n",
        "table.auto_set_font_size(False)\n",
        "table.set_fontsize(10)\n",
        "table.scale(1.2, 1.2) # Adjust scale for better fit\n",
        "\n",
        "plt.title('Classification Report (Original Class vs K-means Cluster)', y=0.95, fontsize=14)\n",
        "plt.show()\n",
        "\n",
        "# Print the accuracy\n",
        "print(f\"\\nAcur√°cia (Overall Agreement): {accuracy:.2f}\")\n",
        "\n",
        "# Note on interpreting the Classification Report for K-Means:\n",
        "# Since K-Means is unsupervised, the cluster labels (0, 1, 2) don't have a predefined meaning\n",
        "# corresponding to the original classes ('Class1', 'Class2', 'Class3').\n",
        "# The classification report here shows how well each original class is spread across the generated clusters.\n",
        "# For example, the row for 'Class1' shows the precision, recall, and f1-score for items belonging to 'Class1'\n",
        "# as if we were trying to predict 'Class1' using the cluster labels. This isn't a true supervised\n",
        "# performance metric, but rather an indication of how much the clusters capture the structure of the original classes.\n",
        "# The 'accuracy' reported is the overall accuracy score when the original labels are compared to the cluster labels\n",
        "# as if the cluster labels were predictions. This is often the average recall across the clusters.\n",
        "# To get a more meaningful interpretation, one would typically analyze the confusion matrix and\n",
        "# potentially relabel the clusters to correspond to the original classes based on majority voting within each cluster.\n"
      ],
      "metadata": {
        "id": "LEpP7Gno9Y6b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}