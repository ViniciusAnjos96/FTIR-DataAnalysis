{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO4Z3HQx8NyEPMxM5zkbAfB"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.cross_decomposition import PLSRegression\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_predict\n",
        "from sklearn.metrics import accuracy_score, classification_report, mean_squared_error, r2_score, confusion_matrix"
      ],
      "metadata": {
        "id": "RacK5n1gNQ0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regressão / Regression"
      ],
      "metadata": {
        "id": "VfvWPUoYTYdl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Com categoria / with label"
      ],
      "metadata": {
        "id": "pNuqAY8UMeqs"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d71b8b6a"
      },
      "source": [
        "# Load the dataset\n",
        "try:\n",
        "    df = pd.read_csv('NAME.csv')\n",
        "    print(\"CSV loaded successfully.\")\n",
        "    display(df.head())\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: NAME.csv not found. Please make sure the file is in the correct directory.\")\n",
        "    # Removed !ls -F from print statement, can be run separately if needed.\n",
        "    print(\"You can use `!ls -F` in a new cell to see available files if needed.\")\n",
        "    df = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ae217e0"
      },
      "source": [
        "if df is not None:\n",
        "    # Separate features (X) and target (y)\n",
        "    # The first column is categorical and should be excluded from features.\n",
        "    y = df.iloc[:, 5]  # Target\n",
        "    X = df.iloc[:, 2:] # Features are from the third column onwards.\n",
        "\n",
        "    print(f\"Shape of features (X): {X.shape}\")\n",
        "    print(f\"Shape of target (y): {y.shape}\")\n",
        "\n",
        "    # Display first few rows of X and y\n",
        "    print(\"Features (X) head:\")\n",
        "    display(X.head())\n",
        "    print(\"Target (y) head:\")\n",
        "    display(y.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0f4f48d1"
      },
      "source": [
        "if df is not None:\n",
        "    # Split data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "\n",
        "    # Scale the features\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    print(f\"Shape of scaled training features: {X_train_scaled.shape}\")\n",
        "    print(f\"Shape of scaled testing features: {X_test_scaled.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2de702da"
      },
      "source": [
        "if df is not None:\n",
        "    # Initialize and train the PLS model\n",
        "    # n_components is the number of latent variables to extract\n",
        "    pls = PLSRegression(n_components=2)\n",
        "    pls.fit(X_train_scaled, y_train)\n",
        "\n",
        "    print(\"PLS Regression model trained successfully.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9db26d6"
      },
      "source": [
        "if df is not None:\n",
        "    # Make predictions on the test set\n",
        "    y_pred = pls.predict(X_test_scaled)\n",
        "\n",
        "    # Evaluate the model\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "\n",
        "    print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
        "    print(f\"R-squared (R2): {r2:.4f}\")\n",
        "    print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
        "\n",
        "    # Plotting actual vs. predicted values\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.scatter(y_test, y_pred, alpha=0.7)\n",
        "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2) # Diagonal line\n",
        "    plt.xlabel('Actual Class Values')\n",
        "    plt.ylabel('Predicted Class Values')\n",
        "    plt.title('PLS Regression: Actual vs. Predicted Values')\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if df is not None and 'pls' in locals():\n",
        "    # Get PLS weights and Y scores\n",
        "    x_weights = pls.x_weights_  # Shape: (n_features, n_components)\n",
        "    y_scores = pls.y_scores_    # Shape: (n_samples, n_components)\n",
        "\n",
        "    # Calculate the sum of squares of Y scores for each component\n",
        "    ss_y_scores = np.sum(y_scores**2, axis=0) # Shape: (n_components,)\n",
        "\n",
        "    # Calculate VIP scores\n",
        "    # p is the number of features\n",
        "    p = X.shape[1]\n",
        "    # Calculate the numerator part: sum_a (w_ja^2 * SS_a)\n",
        "    numerator = np.sum(x_weights**2 * ss_y_scores, axis=1)\n",
        "    # Calculate the denominator part: sum_a (SS_a)\n",
        "    denominator = np.sum(ss_y_scores)\n",
        "\n",
        "    # Final VIP calculation\n",
        "    vip_scores = np.sqrt(p * numerator / denominator)\n",
        "\n",
        "    # Create a DataFrame for better visualization\n",
        "    vip_df = pd.DataFrame({\n",
        "        'Variable': X.columns,\n",
        "        'VIP Score': vip_scores\n",
        "    })\n",
        "\n",
        "    # Sort by VIP Score in descending order\n",
        "    vip_df = vip_df.sort_values(by='VIP Score', ascending=False).reset_index(drop=True)\n",
        "\n",
        "    print(\"\\nVariable Importance in Projection (VIP Scores):\")\n",
        "    display(vip_df)\n",
        "else:\n",
        "    print(\"PLS model not found or data not loaded. Please ensure previous cells ran successfully.\")"
      ],
      "metadata": {
        "id": "r3W1Nphu5GDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sem categoria"
      ],
      "metadata": {
        "id": "dSxXaR_bDfZ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "try:\n",
        "    df = pd.read_csv('NAME.csv', sep=';')\n",
        "    print(\"CSV loaded successfully.\")\n",
        "    display(df.head())\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: NAME.csv not found. Please make sure the file is in the correct directory.\")\n",
        "    # Removed !ls -F from print statement, can be run separately if needed.\n",
        "    print(\"You can use `!ls -F` in a new cell to see available files if needed.\")\n",
        "    df = None"
      ],
      "metadata": {
        "id": "1FAeDbdSDcrV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if df is not None:\n",
        "    # Separate features (X) and target (y)\n",
        "    # The first column is now assumed to be the class/target variable\n",
        "    y = df.iloc[:, 4]  # First column\n",
        "    X = df.iloc[:, 1:] # Remaining columns are features (from second column onwards)\n",
        "\n",
        "    print(f\"Shape of features (X): {X.shape}\")\n",
        "    print(f\"Shape of target (y): {y.shape}\")\n",
        "\n",
        "    # Display first few rows of X and y\n",
        "    print(\"Features (X) head:\")\n",
        "    display(X.head())\n",
        "    print(\"Target (y) head:\")\n",
        "    display(y.head())"
      ],
      "metadata": {
        "id": "kB4_S5_YGVhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if df is not None:\n",
        "    # Split data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "\n",
        "    # Scale the features\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    print(f\"Shape of scaled training features: {X_train_scaled.shape}\")\n",
        "    print(f\"Shape of scaled testing features: {X_test_scaled.shape}\")"
      ],
      "metadata": {
        "id": "S5uxh0UWGX-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if df is not None:\n",
        "    # Initialize and train the PLS model\n",
        "    # n_components is the number of latent variables to extract\n",
        "    pls = PLSRegression(n_components=5)\n",
        "    pls.fit(X_train_scaled, y_train)\n",
        "\n",
        "    print(\"PLS Regression model trained successfully.\")"
      ],
      "metadata": {
        "id": "SG1U2gxEGZ5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if df is not None:\n",
        "    # Make predictions on the test set\n",
        "    y_pred = pls.predict(X_test_scaled)\n",
        "\n",
        "    # Evaluate the model\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "\n",
        "    print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
        "    print(f\"R-squared (R2): {r2:.4f}\")\n",
        "    print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
        "\n",
        "    # Plotting actual vs. predicted values\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.scatter(y_test, y_pred, alpha=0.7)\n",
        "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2) # Diagonal line\n",
        "    plt.xlabel('Actual Class Values')\n",
        "    plt.ylabel('Predicted Class Values')\n",
        "    plt.title('PLS Regression: Actual vs. Predicted Values')\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "zLlYMQaqGcJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if df is not None and 'pls' in locals():\n",
        "    # Get PLS weights and Y scores\n",
        "    x_weights = pls.x_weights_  # Shape: (n_features, n_components)\n",
        "    y_scores = pls.y_scores_    # Shape: (n_samples, n_components)\n",
        "\n",
        "    # Calculate the sum of squares of Y scores for each component\n",
        "    ss_y_scores = np.sum(y_scores**2, axis=0) # Shape: (n_components,)\n",
        "\n",
        "    # Calculate VIP scores\n",
        "    # p is the number of features\n",
        "    p = X.shape[1]\n",
        "    # Calculate the numerator part: sum_a (w_ja^2 * SS_a)\n",
        "    numerator = np.sum(x_weights**2 * ss_y_scores, axis=1)\n",
        "    # Calculate the denominator part: sum_a (SS_a)\n",
        "    denominator = np.sum(ss_y_scores)\n",
        "\n",
        "    # Final VIP calculation\n",
        "    vip_scores = np.sqrt(p * numerator / denominator)\n",
        "\n",
        "    # Create a DataFrame for better visualization\n",
        "    vip_df = pd.DataFrame({\n",
        "        'Variable': X.columns,\n",
        "        'VIP Score': vip_scores\n",
        "    })\n",
        "\n",
        "    # Sort by VIP Score in descending order\n",
        "    vip_df = vip_df.sort_values(by='VIP Score', ascending=False).reset_index(drop=True)\n",
        "\n",
        "    print(\"\\nVariable Importance in Projection (VIP Scores):\")\n",
        "    display(vip_df)\n",
        "else:\n",
        "    print(\"PLS model not found or data not loaded. Please ensure previous cells ran successfully.\")"
      ],
      "metadata": {
        "id": "5ljZUDemGeQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Discriminant Analysis"
      ],
      "metadata": {
        "id": "6h_2qIRnMJhz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# 1️⃣ Carregar dados / load data\n",
        "# ==========================\n",
        "df = pd.read_csv(\"NAME.csv\")\n",
        "display(df.head())\n",
        "\n",
        "# Primeira coluna é o target / first column is target\n",
        "y_raw = df.iloc[:, 0]\n",
        "X = df.iloc[:, 1:]"
      ],
      "metadata": {
        "id": "R6bhKBN1MnSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# 2️⃣ Codificar variável alvo / Encode target variable\n",
        "# ==========================\n",
        "label_enc = LabelEncoder()\n",
        "y_encoded = label_enc.fit_transform(y_raw)\n",
        "\n",
        "onehot = OneHotEncoder(sparse_output=False)\n",
        "y_onehot = onehot.fit_transform(y_encoded.reshape(-1, 1))\n",
        "\n",
        "# ==========================\n",
        "# 3️⃣ Separar treino e teste / Split test and train\n",
        "# ==========================\n",
        "X_train, X_test, y_train, y_test, y_encoded_train, y_encoded_test = train_test_split(\n",
        "    X, y_onehot, y_encoded,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y_encoded\n",
        ")\n",
        "\n",
        "print(f\"Shape of scaled training features: {X_train.shape}\")\n",
        "print(f\"Shape of scaled testing features: {X_test.shape}\")"
      ],
      "metadata": {
        "id": "6P2w4tJHMrx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# 4️⃣ Padronização + PLS / Standardization + PLS\n",
        "# ==========================\n",
        "n_comp = 2 # number of labels/categories / número de variáveis/categorias\n",
        "\n",
        "# Initialize and fit the scaler\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# Initialize and fit the PLS model\n",
        "pls_da_model = PLSRegression(n_components=n_comp)\n",
        "pls_da_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(\"PLS model trained successfully.\")"
      ],
      "metadata": {
        "id": "Z3rYEN5jMubp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# 5️⃣ Predição / Prediction\n",
        "# ==========================\n",
        "# Scale the test features\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "y_pred_continuous = pls_da_model.predict(X_test_scaled)\n",
        "\n",
        "y_pred_class = np.argmax(y_pred_continuous, axis=1)\n",
        "y_test_class = np.argmax(y_test, axis=1)\n",
        "\n",
        "# ==========================\n",
        "# 6️⃣ Métricas / Metric\n",
        "# ==========================\n",
        "print(\"Accuracy:\", accuracy_score(y_test_class, y_pred_class))\n",
        "print(\"\\nClassification report:\\n\")\n",
        "print(classification_report(\n",
        "    y_test_class,\n",
        "    y_pred_class,\n",
        "    target_names=label_enc.classes_\n",
        "))\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred_continuous)\n",
        "r2 = r2_score(y_test, y_pred_continuous)\n",
        "\n",
        "print(\"\\nMSE:\", mse)\n",
        "print(\"R2:\", r2)\n",
        "\n",
        "# ==========================\n",
        "# 7️⃣ Q²\n",
        "# ==========================\n",
        "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "y_cv_pred = cross_val_predict(pls_da_model, X_train_scaled, y_train, cv=cv) # Changed pls_da to pls_da_model\n",
        "\n",
        "# Use y_train for Q2 calculation as y_cv_pred is based on the training set\n",
        "press = np.sum((y_train - y_cv_pred) ** 2)\n",
        "tss = np.sum((y_train - np.mean(y_train, axis=0)) ** 2)\n",
        "\n",
        "q2 = 1 - (press / tss)\n",
        "\n",
        "print(\"Q2:\", q2)\n",
        "\n",
        "# ==========================\n",
        "# 8️⃣ Matriz de Confusão / Confusion matrix\n",
        "# ==========================\n",
        "cm = confusion_matrix(y_test_class, y_pred_class)\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\",\n",
        "            xticklabels=label_enc.classes_,\n",
        "            yticklabels=label_enc.classes_,\n",
        "            cmap=\"Blues\")\n",
        "\n",
        "plt.xlabel(\"Predict\")\n",
        "plt.ylabel(\"Real\")\n",
        "plt.title(\"Confusion Matrix - PLS-DA\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oQ6DaJ9wMzY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# 9️⃣ Score Plot (Comp1 vs Comp2)\n",
        "# ==========================\n",
        "\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "scores = pls_da_model.transform(X_train_scaled)\n",
        "\n",
        "plt.figure(figsize=(7, 6))\n",
        "\n",
        "for i, species in enumerate(label_enc.classes_):\n",
        "    plt.scatter(scores[y_encoded_train == i, 0],\n",
        "                scores[y_encoded_train == i, 1],\n",
        "                label=species,\n",
        "                alpha=0.7)\n",
        "\n",
        "plt.xlabel(\"Component 1\")\n",
        "plt.ylabel(\"Component 2\")\n",
        "plt.title(\"Score Plot PLS-DA\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0RavfizMKX5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# 10. VIP Scores\n",
        "# ==========================\n",
        "if 'pls_da_model' in locals():\n",
        "    # Get PLS weights and Y scores\n",
        "    # x_weights_ are the weights for the X variables\n",
        "    x_weights = pls_da_model.x_weights_  # Shape: (n_features, n_components)\n",
        "    # y_scores_ are the scores for the Y variables (target)\n",
        "    y_scores = pls_da_model.y_scores_    # Shape: (n_samples, n_components)\n",
        "\n",
        "    # Calculate the sum of squares of Y scores for each component\n",
        "    ss_y_scores = np.sum(y_scores**2, axis=0) # Shape: (n_components,)\n",
        "\n",
        "    # Calculate VIP scores\n",
        "    p = X.shape[1] # Number of features\n",
        "\n",
        "    # Calculate the numerator part: sum_a (w_ja^2 * SS_a)\n",
        "    numerator = np.sum(x_weights**2 * ss_y_scores, axis=1)\n",
        "    # Calculate the denominator part: sum_a (SS_a)\n",
        "    denominator = np.sum(ss_y_scores)\n",
        "\n",
        "    # Final VIP calculation\n",
        "    vip_scores = np.sqrt(p * numerator / denominator)\n",
        "\n",
        "    # Create a DataFrame for better visualization\n",
        "    vip_df = pd.DataFrame({\n",
        "        'Variable': X.columns,\n",
        "        'VIP Score': vip_scores\n",
        "    })\n",
        "\n",
        "    # Sort by VIP Score in descending order\n",
        "    vip_df = vip_df.sort_values(by='VIP Score', ascending=False).reset_index(drop=True)\n",
        "\n",
        "    print(\"\\nVariable Importance in Projection (VIP Scores) for PLS-DA:\")\n",
        "    display(vip_df)\n",
        "\n",
        "    # Save the VIP scores to a CSV file\n",
        "    vip_df.to_csv('VIP.csv', index=False)\n",
        "    print(\"VIP scores saved to VIP.csv\")\n",
        "else:\n",
        "    print(\"PLS-DA model (pls_da_model) not found. Please ensure previous cells ran successfully.\")"
      ],
      "metadata": {
        "id": "tEZv0ZjJReYo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}