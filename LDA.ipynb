{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPMgfye/trbLr5Vlq96/PCG"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "source": [
        "# LDA\n",
        "# Change the NAME.csv\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np # Importar numpy para usar unique()\n",
        "from sklearn.preprocessing import LabelEncoder # Importar LabelEncoder\n",
        "\n",
        "# Carregar o arquivo CSV\n",
        "# A primeira coluna (index 0) é a classe, as colunas subsequentes são os espectros (número de onda)\n",
        "df = pd.read_csv('NAME.csv')\n",
        "\n",
        "# Separar as features (X) e o target (y)\n",
        "# Ignoramos a primeira linha que contém o número de onda, assumindo que o pandas lê corretamente as colunas.\n",
        "# A primeira coluna é a classe.\n",
        "X = df.iloc[:, 1:]  # Todas as colunas exceto a primeira\n",
        "y = df.iloc[:, 0]   # A primeira coluna é a classe\n",
        "\n",
        "# Converter os rótulos de classe string para numéricos usando Label Encoding\n",
        "# Isso é necessário para que o Matplotlib possa mapear as classes para cores no scatter plot\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Dividir os dados em conjunto de treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42) # Usar y_encoded aqui para o treino\n",
        "\n",
        "# Inicializar e treinar o modelo LDA\n",
        "lda = LinearDiscriminantAnalysis()\n",
        "lda.fit(X_train, y_train)\n",
        "\n",
        "# Fazer previsões no conjunto de teste\n",
        "y_pred = lda.predict(X_test)\n",
        "\n",
        "# Avaliar o modelo\n",
        "# É importante usar os rótulos originais (ou decodificados) para o classification_report e confusion_matrix\n",
        "# Para o classification_report e confusion_matrix, precisamos dos rótulos originais ou decodificados\n",
        "# Vamos decodificar y_test e y_pred para a avaliação\n",
        "y_test_decoded = label_encoder.inverse_transform(y_test)\n",
        "y_pred_decoded = label_encoder.inverse_transform(y_pred)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test_decoded, y_pred_decoded))\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "cm = confusion_matrix(y_test_decoded, y_pred_decoded, labels=label_encoder.classes_) # Especificar os rótulos para garantir a ordem correta\n",
        "print(cm)\n",
        "\n",
        "# Visualizar a matriz de confusão\n",
        "plt.figure(figsize=(8, 6))\n",
        "# Usar os rótulos decodificados para os ticklabels\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Visualizar os resultados do LDA (se houver mais de uma dimensão discriminante)\n",
        "# LDA pode reduzir a dimensionalidade para um máximo de n_classes - 1 dimensões.\n",
        "\n",
        "# Transformar os dados para a espaço LDA\n",
        "X_lda = lda.transform(X) # Transformar os dados originais X, não os de treino ou teste\n",
        "\n",
        "# Obter o número de componentes discriminantes\n",
        "# O número de componentes é min(n_classes - 1, n_features).\n",
        "# Como estamos plotando, geralmente nos preocupamos com as primeiras componentes.\n",
        "# Podemos inferir o número de componentes a partir da forma de X_lda ou do número de classes.\n",
        "n_components = X_lda.shape[1] # O número de colunas em X_lda é o número de componentes\n",
        "\n",
        "# Alternativamente, você pode contar o número de classes únicas\n",
        "n_classes = len(label_encoder.classes_) # Usar o número de classes únicas do label encoder\n",
        "# n_components = min(n_classes - 1, X.shape[1])\n",
        "\n",
        "\n",
        "if n_components > 1:\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    # Usar X_lda[:, 0] e X_lda[:, 1] para as duas primeiras componentes\n",
        "    # Usar y_encoded para a colorização\n",
        "    scatter = plt.scatter(X_lda[:, 0], X_lda[:, 1], c=y_encoded, cmap='viridis', edgecolors='k', s=50)\n",
        "    plt.xlabel('LD1')\n",
        "    plt.ylabel('LD2')\n",
        "    plt.title('LDA of FTIR Spectra')\n",
        "    # Criar uma colorbar com os rótulos originais\n",
        "    cbar = plt.colorbar(scatter)\n",
        "    cbar.set_label('Class')\n",
        "    # Definir os ticks e labels da colorbar\n",
        "    tick_locs = (y_encoded.min() + y_encoded.max()) / (2 * n_classes) + np.arange(n_classes) * (y_encoded.max() - y_encoded.min() + 1) / n_classes\n",
        "    cbar.set_ticks(tick_locs)\n",
        "    cbar.set_ticklabels(label_encoder.classes_)\n",
        "    plt.show()\n",
        "elif n_components == 1:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    # Usar X_lda[:, 0] para a primeira componente\n",
        "    # Usar y_encoded para a colorização\n",
        "    sns.histplot(x=X_lda[:, 0], hue=y_encoded, multiple=\"stack\", kde=True, palette='viridis')\n",
        "    plt.xlabel('LD1')\n",
        "    plt.title('LDA of FTIR Spectra (1D)')\n",
        "    # Para o histplot, a legenda é gerada automaticamente com os valores numéricos.\n",
        "    # Poderíamos tentar customizar a legenda se necessário, mas para uma simples visualização\n",
        "    # com 1D, os números podem ser aceitáveis ou pode-se adicionar uma anotação.\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"LDA did not produce any discriminant components.\")\n",
        "\n",
        "\n",
        "# Se você quiser usar o modelo treinado para prever novas amostras:\n",
        "# Lembre-se de que o modelo foi treinado com rótulos numéricos.\n",
        "# Se você prever uma nova amostra, o resultado será um número.\n",
        "# Você precisará usar label_encoder.inverse_transform() para obter o rótulo original.\n",
        "# new_spectrum = [seu_novo_espectro_aqui]\n",
        "# predicted_class_encoded = lda.predict([new_spectrum])\n",
        "# predicted_class_decoded = label_encoder.inverse_transform(predicted_class_encoded)\n",
        "# print(f\"Predicted class for new spectrum: {predicted_class_decoded[0]}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "X6pFAIdttYcn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Top 3 wavenumbers with highest absolute weights in LD1\n",
        "\n",
        "import numpy as np\n",
        "# Para identificar os pesos das features (números de onda), podemos analisar os coeficientes\n",
        "# do modelo LDA. Os coeficientes indicam a importância de cada feature na combinação linear\n",
        "# que forma as componentes discriminantes.\n",
        "\n",
        "# Obter os coeficientes do modelo LDA\n",
        "# Para o LDA, os coeficientes estão em `lda.coef_`.\n",
        "# A forma é (n_classes - 1, n_features) ou (n_components, n_features)\n",
        "# onde n_components é o número de componentes discriminantes geradas.\n",
        "lda_coefficients = lda.coef_\n",
        "\n",
        "# Os números de onda correspondem aos nomes das colunas em X.\n",
        "# A primeira linha do arquivo original (que foi ignorada pelo pandas) contém os números de onda.\n",
        "# Precisamos carregar essa linha separadamente ou assumir que os nomes das colunas do DataFrame X\n",
        "# correspondem aos números de onda se o CSV tiver cabeçalho.\n",
        "# Se o CSV não tem cabeçalho, precisaremos ler a primeira linha manualmente.\n",
        "\n",
        "# Assumindo que a primeira linha do arquivo original contém os números de onda\n",
        "# Vamos reler a primeira linha do arquivo CSV para obter os nomes das colunas\n",
        "with open('AMP_preprocess.csv', 'r') as f:\n",
        "    first_line = f.readline().strip()\n",
        "\n",
        "# A primeira linha contém a classe e depois os números de onda separados por vírgula\n",
        "# Separar os números de onda (ignorando o primeiro elemento que é o nome da coluna da classe)\n",
        "wavenumbers = first_line.split(',')[1:]\n",
        "\n",
        "# Converter os números de onda para tipo numérico (float, por exemplo)\n",
        "# Isso garante que a ordenação seja numérica e não lexicográfica\n",
        "wavenumbers = [float(wn) for wn in wavenumbers]\n",
        "\n",
        "\n",
        "# Para cada componente discriminante, podemos encontrar as features com os maiores pesos (em magnitude)\n",
        "# Se houver apenas uma componente discriminante (n_components == 1), analisamos os pesos dessa componente.\n",
        "# Se houver múltiplas componentes, podemos analisar a primeira componente ou a combinação delas.\n",
        "# Geralmente, a primeira componente discriminante (LD1) explica a maior parte da variância entre as classes.\n",
        "# Vamos analisar os pesos da primeira componente discriminante (lda_coefficients[0]).\n",
        "\n",
        "if n_components >= 1:\n",
        "    # Os pesos da primeira componente discriminante\n",
        "    weights_ld1 = lda_coefficients[0]\n",
        "\n",
        "    # Obter os índices das features com os maiores pesos em magnitude (valor absoluto)\n",
        "    # Usar np.argsort para obter os índices que ordenariam os pesos por magnitude\n",
        "    # Pegar os últimos 3 índices para obter os 3 maiores pesos em magnitude\n",
        "    top_3_indices = np.argsort(np.abs(weights_ld1))[-3:]\n",
        "\n",
        "    # Ordenar os índices para obter os pesos em ordem decrescente de magnitude\n",
        "    top_3_indices = top_3_indices[::-1]\n",
        "\n",
        "    print(\"\\nTop 3 wavenumbers with highest absolute weights in LD1:\")\n",
        "    for i in top_3_indices:\n",
        "        # Usar os índices para obter o número de onda e o peso correspondente\n",
        "        wavenumber = wavenumbers[i]\n",
        "        weight = weights_ld1[i]\n",
        "        print(f\"Wavenumber: {wavenumber}, Weight (LD1): {weight:.4f}\")\n",
        "\n",
        "    # Se houver mais de uma componente, você pode repetir a análise para outras componentes\n",
        "    # ou considerar uma combinação dos pesos. Para simplificar, focamos na LD1 que é a mais importante.\n",
        "\n",
        "else:\n",
        "    print(\"\\nLDA did not produce any discriminant components to analyze weights.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "quyq_hoDtrwu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}