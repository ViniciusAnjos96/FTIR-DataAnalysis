{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP8oXJZ1+SIg1AOXo4rYVLu"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# === Pacotes necessários / Required packages ===\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from itertools import combinations"
      ],
      "metadata": {
        "id": "2AcwqTBXfVWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sem classe indexada / No indexed class"
      ],
      "metadata": {
        "id": "GoxtNx8CkmYO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 1. Ler os dados .XLSX / Read .XLSX data =====\n",
        "dados = pd.read_excel(\"NAME.xlsx\")\n",
        "print(dados.head())"
      ],
      "metadata": {
        "id": "TMmsszr4vfjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Ler os dados .CSV / Read .CSV data ===\n",
        "dados = pd.read_csv('NAME.csv', sep=';')  # especifica o separador / specifies the separator\n",
        "print(dados.head())"
      ],
      "metadata": {
        "id": "YwzMo2EZfZlk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Padronização dos dados / Data standardization ===\n",
        "scaler = StandardScaler()\n",
        "dados_padronizados = scaler.fit_transform(dados)"
      ],
      "metadata": {
        "id": "XSSBBeLqfiDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === PCA ===\n",
        "pca = PCA()\n",
        "pca.fit(dados_padronizados)\n",
        "\n",
        "# Autovetores / Eigenvectors (loadings)\n",
        "autovetores = pca.components_.T\n",
        "# Autovalores (variância explicada em valores absolutos) / Eigenvalues ​​(variance explained in absolute values)\n",
        "explained_variances = pca.explained_variance_\n",
        "# Proporção da variância explicada (%) / Proportion of variance explained (%)\n",
        "variancia_explicada_pct = pca.explained_variance_ratio_\n",
        "\n",
        "# === Scree Plot ===\n",
        "plt.figure()\n",
        "plt.plot(np.arange(1, len(explained_variances)+1), explained_variances, 'o-', color='blue')\n",
        "plt.title(\"Scree Plot\")\n",
        "plt.xlabel(\"Principal Component\")\n",
        "plt.ylabel(\"Eigenvalues\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4FRJ2myWfnv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Biplot (PC1 vs PC2) ===\n",
        "scores = pca.transform(dados_padronizados)\n",
        "plt.figure(figsize=(7,6))\n",
        "plt.scatter(scores[:,0], scores[:,1], alpha=0.6, c=\"steelblue\")\n",
        "\n",
        "for i, var in enumerate(dados.columns):\n",
        "    plt.arrow(0, 0, autovetores[i,0]*max(scores[:,0]), autovetores[i,1]*max(scores[:,1]),\n",
        "              color=\"red\", alpha=0.7, head_width=0.1)\n",
        "    plt.text(autovetores[i,0]*max(scores[:,0])*1.1,\n",
        "             autovetores[i,1]*max(scores[:,1])*1.1,\n",
        "             var, color=\"red\", ha=\"center\", va=\"center\")\n",
        "\n",
        "plt.title(\"Biplot PCA\")\n",
        "plt.xlabel(f\"PC1 ({variancia_explicada_pct[0]*100:.2f}%)\")\n",
        "plt.ylabel(f\"PC2 ({variancia_explicada_pct[1]*100:.2f}%)\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XKeDuo-5fp-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Seleção de componentes / Component selection ===\n",
        "num_componentes = 6 # muda aqui o número de PCs / change the number of PCs here\n",
        "autovetores_selecionados = autovetores[:, :num_componentes]\n",
        "\n",
        "# Projeção dos dados padronizados / Projection of standardized data\n",
        "dados_projetados_pca = dados_padronizados @ autovetores_selecionados\n",
        "dados_projetados_pca_df = pd.DataFrame(\n",
        "    dados_projetados_pca,\n",
        "    columns=[f\"PC{i+1}\" for i in range(num_componentes)]\n",
        ")\n",
        "\n",
        "print(dados_projetados_pca_df)"
      ],
      "metadata": {
        "id": "akLYkFI4fsBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Gráficos de dispersão entre PCs / Scatterplots between PCs ===\n",
        "componentes = [f\"PC{i}\" for i in range(1, 6)] # muda aqui o número de PCs / change the number of PCs here\n",
        "from itertools import combinations\n",
        "combinacoes = list(combinations(componentes, 2))\n",
        "\n",
        "for x_comp, y_comp in combinacoes:\n",
        "    x_index = int(x_comp.replace(\"PC\", \"\"))\n",
        "    y_index = int(y_comp.replace(\"PC\", \"\"))\n",
        "\n",
        "    plt.figure(figsize=(6,5))\n",
        "    sns.scatterplot(data=dados_projetados_pca_df, x=x_comp, y=y_comp, s=50, color=\"steelblue\", alpha=0.6)\n",
        "    sns.kdeplot(data=dados_projetados_pca_df, x=x_comp, y=y_comp, color=\"darkred\", linewidth=0.7)\n",
        "\n",
        "    plt.title(\"PCA Visualization: Data Structure\")\n",
        "    plt.xlabel(f\"Principal Component {x_index} ({variancia_explicada_pct[x_index-1]*100:.2f}%)\")\n",
        "    plt.ylabel(f\"rincipal Component {y_index} ({variancia_explicada_pct[y_index-1]*100:.2f}%)\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "U5B39K3XftxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Loadings ===\n",
        "loadings_df = pd.DataFrame(\n",
        "    autovetores,\n",
        "    index=dados.columns,\n",
        "    columns=[f\"PC{i+1}\" for i in range(len(autovetores[0]))]\n",
        ")\n",
        "\n",
        "print(loadings_df)\n",
        "\n",
        "# Salvar loadings em CSV e Excel / Save loadings in CSV and Excel\n",
        "loadings_df.to_csv(\"pca_loadings.csv\")\n",
        "loadings_df.to_excel(\"pca_loadings.xlsx\")\n",
        "\n",
        "print(\"pca_loadings.csv and pca_loadings.xlsx saved.\")"
      ],
      "metadata": {
        "id": "U06NkqNZfvdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Do9oh46VfSj0"
      },
      "outputs": [],
      "source": [
        "# === Variância explicada / Variance explained ===\n",
        "explained_variance_ratio = variancia_explicada_pct\n",
        "cumulative_explained_variance = np.cumsum(explained_variance_ratio)\n",
        "\n",
        "variance_table = pd.DataFrame({\n",
        "    \"Principal_Component\": np.arange(1, len(explained_variance_ratio)+1),\n",
        "    \"Proportion_of_Variance\": explained_variance_ratio,\n",
        "    \"Cumulative_Proportion\": cumulative_explained_variance\n",
        "})\n",
        "\n",
        "print(variance_table)\n",
        "\n",
        "variance_table.to_csv(\"variance_table.csv\", index=False)\n",
        "variance_table.to_excel(\"variance_table.xlsx\", index=False)\n",
        "\n",
        "print(\"variance_table.xlsx saved.\")\n",
        "print(\"variance_table.csv saved.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reduzindo a dimensionalidade / Reducing dimensionality\n",
        "\n"
      ],
      "metadata": {
        "id": "jQ_9m1G_hrMr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Escolha quantos PCs você quer considerar / Choose how many PCs you want to consider\n",
        "n_pcs = 6  # <<--- altere esse valor conforme necessário / change this value as needed\n",
        "\n",
        "# Calcula a soma dos quadrados dos loadings / Calculates the sum of the squares of the loadings\n",
        "pcs_de_interesse = [f'PC{i+1}' for i in range(n_pcs)]\n",
        "contribuicoes = (loadings_df[pcs_de_interesse] ** 2).sum(axis=1)\n",
        "\n",
        "# Ordena por importância / Sort by importance\n",
        "contribuicoes_ordenadas = contribuicoes.sort_values(ascending=False)\n",
        "\n",
        "# Exibe o top N / Displays the top N\n",
        "top_n = 6  # <<--- altere esse valor conforme necessário / change this value as needed\n",
        "print(f\"\\nTop {top_n} most important variables (based on {n_pcs} first PCs):\")\n",
        "top_variaveis = contribuicoes_ordenadas.head(top_n)\n",
        "print(contribuicoes_ordenadas.head(top_n))"
      ],
      "metadata": {
        "id": "4wM_JOKIhuLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Limpa o DataFrame original para manter apenas as variáveis selecionadas / Clears the original DataFrame to keep only the selected variables\n",
        "dados_filtrados = dados[top_variaveis.index.tolist()]\n",
        "\n",
        "# (Opcional) Substituir o DataFrame original, se quiser sobrescrever: / (Optional) Replace the original DataFrame, if you want to overwrite it:\n",
        "# dados = dados_filtrados\n",
        "\n",
        "# Exibe as primeiras linhas do novo DataFrame / Displays the first few rows of the new DataFrame\n",
        "print(\"\\nDataFrame 'data' after filtering by the most important variables:\")\n",
        "print(dados_filtrados.head())"
      ],
      "metadata": {
        "id": "BPOy1On8qPIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Salvar os dados filtrados em um arquivo Excel / Save the filtered data to an Excel file\n",
        "dados_filtrados.to_excel('dados_filtrados.xlsx', index=False)\n",
        "\n",
        "print(\"✅ File 'data_filtrados.xlsx' saved successfully.\")"
      ],
      "metadata": {
        "id": "hQTnreViqpE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Salvar os dados filtrados em um arquivo CSV / Save the filtered data to a CSV file\n",
        "dados_filtrados.to_csv('dados_filtrados.csv', index=False)\n",
        "\n",
        "print(\"✅ File 'data_filtrados.csv' saved successfully.\")"
      ],
      "metadata": {
        "id": "bhQ_A2oGv9sx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Com classe indexada / With indexed class"
      ],
      "metadata": {
        "id": "eUR2x_AGlnzV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 1. Ler os dados .XLSX / Read .XLSX data =====\n",
        "dados = pd.read_excel(\"NAME.xlsx\")\n",
        "print(dados.head())"
      ],
      "metadata": {
        "id": "21YdNQr5wL3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Ler os dados .CSV / Read .CSV data ===\n",
        "dados = pd.read_csv('NAME.csv', sep=',')  # especifica o separador / specifies the separator\n",
        "print(dados.head())"
      ],
      "metadata": {
        "id": "Meur8eSdwPMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separar classes (primeira coluna) dos preditores / Separate classes (first column) of predictors\n",
        "classe = dados.iloc[:, 0]     # primeira coluna = classes / first column = classes\n",
        "X = dados.iloc[:, 1:]         # resto = variáveis numéricas / other = numeric variables\n",
        "\n",
        "print(\"Classes detected:\\n\", classe.unique())\n",
        "print(\"\\nSamples:\\n\", X.head())"
      ],
      "metadata": {
        "id": "jk_Z7w8vl10q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Padronização / Standardization ===\n",
        "scaler = StandardScaler()\n",
        "X_padronizado = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "uk5ZOGwZl4pK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === PCA ===\n",
        "pca = PCA()\n",
        "pca.fit(X_padronizado)\n",
        "\n",
        "# Autovetores / Eigenvectors (loadings)\n",
        "autovetores = pca.components_.T\n",
        "explained_variances = pca.explained_variance_\n",
        "variancia_explicada_pct = pca.explained_variance_ratio_\n",
        "\n",
        "# === Scree Plot ===\n",
        "plt.figure()\n",
        "plt.plot(np.arange(1, len(explained_variances)+1), explained_variances, 'o-', color='blue')\n",
        "plt.title(\"Scree Plot\")\n",
        "plt.xlabel(\"Componente Principal\")\n",
        "plt.ylabel(\"Autovalor\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FWku8Q1OmCRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Biplot (PC1 vs PC2) ===\n",
        "scores = pca.transform(X_padronizado)\n",
        "plt.figure(figsize=(7,6))\n",
        "\n",
        "# cor dos pontos pela classe / color of points by class\n",
        "sns.scatterplot(x=scores[:,0], y=scores[:,1], hue=classe, palette=\"tab10\", alpha=0.7)\n",
        "\n",
        "for i, var in enumerate(X.columns):\n",
        "    plt.arrow(0, 0, autovetores[i,0]*max(scores[:,0]), autovetores[i,1]*max(scores[:,1]),\n",
        "              color=\"red\", alpha=0.7, head_width=0.1)\n",
        "    plt.text(autovetores[i,0]*max(scores[:,0])*1.1,\n",
        "             autovetores[i,1]*max(scores[:,1])*1.1,\n",
        "             var, color=\"red\", ha=\"center\", va=\"center\")\n",
        "\n",
        "plt.title(\"Biplot PCA\")\n",
        "plt.xlabel(f\"PC1 ({variancia_explicada_pct[0]*100:.2f}%)\")\n",
        "plt.ylabel(f\"PC2 ({variancia_explicada_pct[1]*100:.2f}%)\")\n",
        "plt.legend(title=\"Class\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kipFvvsYmRv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Seleção de componentes / Component selection ===\n",
        "num_componentes = 20    # <<--- altere esse valor conforme necessário / change this value as needed\n",
        "autovetores_selecionados = autovetores[:, :num_componentes]\n",
        "X_proj = X_padronizado @ autovetores_selecionados\n",
        "\n",
        "dados_proj_pca_df = pd.DataFrame(\n",
        "    X_proj,\n",
        "    columns=[f\"PC{i+1}\" for i in range(num_componentes)]\n",
        ")\n",
        "dados_proj_pca_df[\"Classe\"] = classe.values  # adiciona classes / add classes\n",
        "\n",
        "print(dados_proj_pca_df.head())"
      ],
      "metadata": {
        "id": "TTTboTlVmULN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Gráficos de dispersão entre PCs / Scatterplots between PCs ===\n",
        "componentes = [f\"PC{i}\" for i in range(1, 6)]\n",
        "combinacoes = list(combinations(componentes, 2))\n",
        "\n",
        "for x_comp, y_comp in combinacoes:\n",
        "    x_index = int(x_comp.replace(\"PC\", \"\"))\n",
        "    y_index = int(y_comp.replace(\"PC\", \"\"))\n",
        "\n",
        "    plt.figure(figsize=(6,5))\n",
        "    sns.scatterplot(data=dados_proj_pca_df, x=x_comp, y=y_comp,\n",
        "                    hue=\"Classe\", palette=\"tab10\", s=50, alpha=0.7)\n",
        "\n",
        "    plt.title(\"PCA Visualization: Data Structure\")\n",
        "    plt.xlabel(f\"Principal Component {x_index} ({variancia_explicada_pct[x_index-1]*100:.2f}%)\")\n",
        "    plt.ylabel(f\"Principal Component {y_index} ({variancia_explicada_pct[y_index-1]*100:.2f}%)\")\n",
        "    plt.legend(title=\"Class\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "oe9gQVNOmV5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Loadings ===\n",
        "loadings_df = pd.DataFrame(\n",
        "    autovetores,\n",
        "    index=X.columns,\n",
        "    columns=[f\"PC{i+1}\" for i in range(len(autovetores[0]))]\n",
        ")\n",
        "\n",
        "print(loadings_df)\n",
        "\n",
        "loadings_df.to_csv(\"pca_loadings.csv\")\n",
        "loadings_df.to_excel(\"pca_loadings.xlsx\")\n",
        "print(\"pca_loadings.csv and pca_loadings.xlsx saved.\")\n"
      ],
      "metadata": {
        "id": "4nSQY66jlrPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Variância explicada / Variance explained ===\n",
        "explained_variance_ratio = variancia_explicada_pct\n",
        "cumulative_explained_variance = np.cumsum(explained_variance_ratio)\n",
        "\n",
        "variance_table = pd.DataFrame({\n",
        "    \"Principal_Component\": np.arange(1, len(explained_variance_ratio)+1),\n",
        "    \"Proportion_of_Variance\": explained_variance_ratio,\n",
        "    \"Cumulative_Proportion\": cumulative_explained_variance\n",
        "})\n",
        "\n",
        "print(variance_table)\n",
        "\n",
        "variance_table.to_csv(\"variance_table.csv\", index=False)\n",
        "variance_table.to_excel(\"variance_table.xlsx\", index=False)\n",
        "print(\"variance_table.xlsx saved.\")"
      ],
      "metadata": {
        "id": "01Ah0EfGmcSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reduzindo a dimensionalidade"
      ],
      "metadata": {
        "id": "gR7YQNMorvYd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Escolha quantos PCs você quer considerar / Choose how many PCs you want to consider\n",
        "n_pcs = 20 # <<--- altere esse valor conforme necessário / change this value as needed\n",
        "\n",
        "# Calcula a soma dos quadrados dos loadings / Calculates the sum of the squares of the loadings\n",
        "pcs_de_interesse = [f'PC{i+1}' for i in range(n_pcs)]\n",
        "contribuicoes = (loadings_df[pcs_de_interesse] ** 2).sum(axis=1)\n",
        "\n",
        "# Ordena por importância / Sort by importance\n",
        "contribuicoes_ordenadas = contribuicoes.sort_values(ascending=False)\n",
        "\n",
        "# Exibe o top N / Displays the top N\n",
        "top_n = 20  # <<--- altere esse valor conforme necessário / change this value as needed\n",
        "print(f\"\\nTop {top_n} most important variables (based on {n_pcs} first PCs):\")\n",
        "top_variaveis = contribuicoes_ordenadas.head(top_n)\n",
        "print(contribuicoes_ordenadas.head(top_n))"
      ],
      "metadata": {
        "id": "kLuYm-MjsM8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Limpa o DataFrame original para manter apenas as variáveis selecionadas / Clears the original DataFrame to keep only the selected variables\n",
        "dados_filtrados = dados[top_variaveis.index.tolist()]\n",
        "\n",
        "# (Opcional) Substituir o DataFrame original, se quiser sobrescrever: / (Optional) Replace the original DataFrame, if you want to overwrite it:\n",
        "# dados = dados_filtrados\n",
        "\n",
        "# Adicionar a coluna 'Classe' de volta como a primeira coluna / Add the 'Class' column back as the first column\n",
        "dados_filtrados.insert(0, 'Classe', classe)\n",
        "\n",
        "# Exibe as primeiras linhas do novo DataFrame / Displays the first few rows of the new DataFrame\n",
        "print(\"\\nDataFrame 'data' after filtering by the most important variables:\")\n",
        "print(dados_filtrados.head())"
      ],
      "metadata": {
        "id": "e5JTAP1vtJyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Salvar os dados filtrados em um arquivo Excel / Save the filtered data to an Excel file\n",
        "dados_filtrados.to_excel('dados_filtrados.xlsx', index=False)\n",
        "\n",
        "print(\"✅ File 'data_filtrados.xlsx' saved successfully.\")"
      ],
      "metadata": {
        "id": "-SDY0oVFtRJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Salvar os dados filtrados em um arquivo CSV / Save the filtered data to a CSV file\n",
        "dados_filtrados.to_csv('dados_filtrados.csv', index=False)\n",
        "\n",
        "print(\"✅ File 'data_filtrados.csv' saved successfully.\")"
      ],
      "metadata": {
        "id": "6XG9BIONwHgJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}